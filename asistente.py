# asistente_investigacion_corregido.py

import streamlit as st
import requests
import time
from datetime import datetime
import io
import csv
import re

# Manejo de importaciones opcionales
try:
    from bs4 import BeautifulSoup
    BEAUTIFULSOUP_AVAILABLE = True
except ImportError:
    BEAUTIFULSOUP_AVAILABLE = False
    st.warning("‚ö†Ô∏è BeautifulSoup no est√° disponible. La b√∫squeda en SciELO no funcionar√°.")

try:
    import google.generativeai as genai
    from google.generativeai import types
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    st.warning("‚ö†Ô∏è Google Generative AI no est√° disponible. Las funciones de IA no funcionar√°n.")

try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    st.warning("‚ö†Ô∏è python-docx no est√° disponible. La exportaci√≥n a DOCX no funcionar√°.")

try:
    from semantic_scholar import SemanticScholar
    SEMANTIC_SCHOLAR_AVAILABLE = True
except ImportError:
    SEMANTIC_SCHOLAR_AVAILABLE = False
    st.warning("‚ö†Ô∏è Semantic Scholar no est√° disponible. La b√∫squeda en Semantic Scholar no funcionar√°.")

# Clase Agente con memoria
class AgenteConMemoria:
    def __init__(self):
        self.memoria = []
    
    def agregar_memoria(self, entrada, salida):
        self.memoria.append({"entrada": entrada, "salida": salida, "timestamp": datetime.now()})
    
    def obtener_memoria(self):
        return self.memoria
    
    def limpiar_memoria(self):
        self.memoria = []

# FUNCIONES DE B√öSQUEDA MEJORADAS CON MANEJO DE ERRORES
def buscar_semantic_scholar(query, max_results=5):
    """B√∫squeda gratuita en Semantic Scholar"""
    if not SEMANTIC_SCHOLAR_AVAILABLE:
        return []
    
    articulos = []
    try:
        scholar = SemanticScholar()
        resultados = scholar.search_paper(query, limit=max_results)
        count = 0
        for paper in resultados:
            articulos.append({
                "titulo": paper.title,
                "autor": ". ".join([author['name'] for author in paper.authors]) if paper.authors else 'Desconocido',
                "a√±o": str(paper.year) if paper.year else "s.f.",
                "publicacion": paper.venue if paper.venue else "",
                "url": paper.url if paper.url else "",
                "fuente": "Semantic Scholar"
            })
            count += 1
            if count >= max_results:
                break
        time.sleep(0.5)
    except Exception as e:
        st.error(f"Error en Semantic Scholar: {e}")
    return articulos

def buscar_scielo(query, max_results=5):
    """B√∫squeda gratuita en SciELO"""
    if not BEAUTIFULSOUP_AVAILABLE:
        st.error("BeautifulSoup no est√° instalado. Instala con: pip install beautifulsoup4")
        return []
    
    articulos = []
    try:
        url = f"https://search.scielo.org/?q={query}&lang=es"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        soup = BeautifulSoup(response.text, 'html.parser')
        resultados = soup.select(".item")
        
        for resultado in resultados[:max_results]:
            try:
                titulo_elem = resultado.select_one(".title")
                autores_elem = resultado.select_one(".authors")
                enlace_elem = resultado.select_one(".line a")
                
                titulo = titulo_elem.text.strip() if titulo_elem else "Sin titulo"
                autores = autores_elem.text.strip() if autores_elem else "Desconocido"
                enlace = enlace_elem["href"] if enlace_elem else ""
                
                articulos.append({
                    "titulo": titulo,
                    "autor": autores,
                    "a√±o": "s.f.",
                    "publicacion": "SciELO",
                    "url": f"https:{enlace}" if enlace else "",
                    "fuente": "SciELO"
                })
            except Exception:
                continue
    except Exception as e:
        st.error(f"Error en SciELO: {e}")
    return articulos

# FUNCIONES DE PROCESAMIENTO DE LENGUAJE MEJORADAS
def extraer_tema_principal(user_input):
    """Extrae el tema real de investigaci√≥n del input del usuario"""
    try:
        # Patr√≥n para detectar preguntas de investigaci√≥n
        patron_pregunta = r'[¬ø]?(qu√©|cuales|como|por qu√©|d√≥nde|cu√°ndo)\s+([^?]+)[?]'
        coincidencia = re.search(patron_pregunta, user_input.lower())
        
        if coincidencia:
            return coincidencia.group(2).strip()
        
        # Eliminar palabras de solicitud metodol√≥gica
        palabras_excluir = ['formula', 'planteamiento', 'problema', 'interrogante', 
                           'redacta', 'elabora', 'desarrolla', 'haz', 'crea', 'genera',
                           'para la', 'sobre', 'acerca de']
        
        tema = user_input.lower()
        for palabra in palabras_excluir:
            tema = tema.replace(palabra, '')
        
        # Limpiar espacios extras y caracteres especiales
        tema = re.sub(r'[^\w\s]', '', tema)
        tema = ' '.join(tema.split())
        
        return tema.strip() if tema.strip() else user_input
    except Exception:
        return user_input

def detectar_tipo_solicitud(user_input):
    """Detecta el tipo de solicitud del usuario"""
    input_lower = user_input.lower()
    
    if any(palabra in input_lower for palabra in ['planteamiento', 'problema', 'pregunta investigaci√≥n']):
        return "planteamiento"
    elif any(palabra in input_lower for palabra in ['objetivos', 'metas', 'prop√≥sitos']):
        return "objetivos"
    elif any(palabra in input_lower for palabra in ['metodolog√≠a', 'm√©todo', 'dise√±o', 'enfoque']):
        return "metodologia"
    elif any(palabra in input_lower for palabra in ['variables', 'operacional']):
        return "variables"
    elif any(palabra in input_lower for palabra in ['resumen', 's√≠ntesis', 'analizar']):
        return "resumen"
    else:
        return "general"

# FUNCIONES DE GENERACI√ìN MEJORADAS
def generar_planteamiento_estructurado(tema, contexto=""):
    """Genera un planteamiento del problema bien estructurado"""
    if not GENAI_AVAILABLE:
        return f"""
        # PLANTEAMIENTO DEL PROBLEMA - {tema}
        
        ## DESCRIPCI√ìN DEL PROBLEMA
        La investigaci√≥n se centra en el an√°lisis de {tema}. Este tema representa un √°rea de creciente importancia en el contexto actual.
        
        ## JUSTIFICACI√ìN
        El estudio de {tema} es relevante debido a su impacto en diversos √°mbitos. La comprensi√≥n de este fen√≥meno puede contribuir significativamente al campo.
        
        ## DELIMITACI√ìN
        La investigaci√≥n se limitar√° al an√°lisis de {tema} en el contexto de {contexto if contexto else 'diversos escenarios'}.
        
        ## PREGUNTAS DE INVESTIGACI√ìN
        1. ¬øCu√°les son los principales factores que influyen en {tema}?
        2. ¬øC√≥mo se manifiesta {tema} en diferentes contextos?
        3. ¬øQu√© estrategias pueden implementarse para abordar los desaf√≠os relacionados con {tema}?
        
        *Nota: Para una generaci√≥n m√°s precisa, instala google-generativeai*
        """
    
    try:
        client = genai.Client()
        
        prompt = f"""
        Como experto en metodolog√≠a de investigaci√≥n, genera un PLANTEAMIENTO DEL PROBLEMA 
        acad√©mico y profesional sobre el tema: "{tema}"
        
        Contexto adicional: {contexto}
        
        Estructura tu respuesta en los siguientes componentes:
        
        # DESCRIPCI√ìN DEL PROBLEMA
        [Describe claramente el problema de investigaci√≥n, su contexto y magnitud]
        
        # JUSTIFICACI√ìN
        [Explica la relevancia acad√©mica, pr√°ctica y social de investigar este problema]
        
        # DELIMITACI√ìN
        [Especifica el alcance, poblaci√≥n y contexto del estudio]
        
        # PREGUNTAS DE INVESTIGACI√ìN
        [Formula 3-5 preguntas de investigaci√≥n espec√≠ficas y relevantes]
        
        Usa un lenguaje acad√©mico formal en espa√±ol. S√© espec√≠fico y evita generalizaciones.
        """
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        
        return response.text.strip()
        
    except Exception as e:
        return f"Error al generar planteamiento: {e}"

def generar_objetivos_estructurados(tema, contexto=""):
    """Genera objetivos de investigaci√≥n estructurados"""
    if not GENAI_AVAILABLE:
        return f"""
        OBJETIVO GENERAL:
        Analizar los aspectos fundamentales de {tema} en el contexto de {contexto if contexto else 'diversos escenarios'}.
        
        OBJETIVOS ESPEC√çFICOS:
        1. Identificar los principales componentes de {tema}
        2. Evaluar el impacto de {tema} en diferentes contextos
        3. Proponer estrategias para optimizar los resultados relacionados con {tema}
        4. Establecer lineamientos para la implementaci√≥n efectiva de soluciones
        
        *Nota: Para una generaci√≥n m√°s precisa, instala google-generativeai*
        """
    
    try:
        client = genai.Client()
        
        prompt = f"""
        Para la investigaci√≥n sobre: "{tema}"
        
        Contexto: {contexto}
        
        Genera objetivos de investigaci√≥n que incluyan:
        
        OBJETIVO GENERAL:
        [Un objetivo principal amplio]
        
        OBJETIVOS ESPEC√çFICOS:
        1. [Objetivo espec√≠fico 1]
        2. [Objetivo espec√≠fico 2] 
        3. [Objetivo espec√≠fico 3]
        4. [Objetivo espec√≠fico 4]
        
        Los objetivos deben ser SMART (espec√≠ficos, medibles, alcanzables, relevantes, temporales)
        y coherentes con el tema de investigaci√≥n.
        """
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        
        return response.text.strip()
        
    except Exception as e:
        return f"Error al generar objetivos: {e}"

def generar_respuesta_general(tema, user_input):
    """Genera respuesta general del asistente"""
    if not GENAI_AVAILABLE:
        return f"""
        Como asistente de investigaci√≥n especializado en {tema}, puedo sugerirte:
        
        - Realizar una b√∫squeda bibliogr√°fica en bases de datos acad√©micas
        - Considerar enfoques metodol√≥gicos mixtos para una comprensi√≥n integral
        - Analizar el contexto espec√≠fico de aplicaci√≥n
        - Identificar variables clave para tu investigaci√≥n
        
        Para respuestas m√°s espec√≠ficas, instala google-generativeai
        """
    
    try:
        client = genai.Client()
        
        prompt = f"""
        Eres un asistente de investigaci√≥n acad√©mica especializado en {tema}.
        
        El usuario pregunta: "{user_input}"
        
        Proporciona una respuesta √∫til, acad√©mica y bien fundamentada. Si es apropiado, sugiere:
        - Enfoques metodol√≥gicos
        - Fuentes de datos relevantes
        - Conceptos clave para investigar
        - Posibles l√≠neas de investigaci√≥n
        
        Respuesta en espa√±ol, formato claro y profesional.
        """
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.7)
        )
        
        return response.text.strip()
        
    except Exception as e:
        return f"Error en la respuesta: {e}"

# FUNCI√ìN DE CHAT COMPLETAMENTE REDISE√ëADA
def chat_con_agente(agente, user_input, contexto_usuario=""):
    """Funci√≥n principal del chat completamente mejorada"""
    try:
        # Extraer el tema real de la consulta
        tema_real = extraer_tema_principal(user_input)
        tipo_solicitud = detectar_tipo_solicitud(user_input)
        
        # Generar respuesta seg√∫n el tipo de solicitud
        if tipo_solicitud == "planteamiento":
            respuesta = generar_planteamiento_estructurado(tema_real, contexto_usuario)
            
        elif tipo_solicitud == "objetivos":
            respuesta = generar_objetivos_estructurados(tema_real, contexto_usuario)
            
        elif tipo_solicitud == "metodologia":
            respuesta = generar_sugerencias_metodologicas("", contexto_usuario or tema_real)
            
        elif tipo_solicitud == "variables":
            respuesta = sugerir_variables_operativas("", contexto_usuario or tema_real)
            
        elif tipo_solicitud == "resumen":
            if hasattr(st.session_state, 'resumen_actual'):
                respuesta = st.session_state.resumen_actual
            else:
                respuesta = "Primero realiza una b√∫squeda acad√©mica para generar res√∫menes."
                
        else:
            respuesta = generar_respuesta_general(tema_real, user_input)
        
        # Guardar en memoria
        agente.agregar_memoria(user_input, respuesta)
        return respuesta
        
    except Exception as e:
        return f"Error en el chat: {e}"

# FUNCIONES ORIGINALES (MANTENIDAS CON MEJOR MANEJO DE ERRORES)
def preparar_texto_para_gemini(articulos):
    texto = ""
    for art in articulos:
        texto += f"T√≠tulo: {art['titulo']}\nAutores: {art['autor']}\nA√±o: {art['a√±o']}\nURL: {art['url']}\n\n"
    return texto

def resumir_articulos_con_gemini(texto):
    if not GENAI_AVAILABLE:
        return "La funcionalidad de resumen con IA no est√° disponible. Instala google-generativeai."
    
    try:
        client = genai.Client()
        prompt = (f"Analiza estos art√≠culos acad√©micos para resumir temas principales, "
                 f"vac√≠os de investigaci√≥n y sugerir l√≠neas de trabajo para un proyecto:\n\n{texto}")
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.2)
        )
        return response.text
    except Exception as e:
        return f"Error al generar resumen: {e}"

def generar_planteamiento_problema(texto_resumen, contexto_usuario):
    if not GENAI_AVAILABLE:
        return "Instala google-generativeai para usar esta funci√≥n."
    
    try:
        client = genai.Client()
        prompt = (
            f"Con base en la siguiente s√≠ntesis de literatura cient√≠fica:\n{texto_resumen}\n\n"
            f"Considerando que el investigador se interesa en: {contexto_usuario}\n"
            "Genera un planteamiento del problema estructurado para un proyecto de investigaci√≥n que incluya:\n"
            ". Descripci√≥n clara del problema\n"
            ". Justificaci√≥n de la investigaci√≥n\n"
            ". Delimitaci√≥n del campo o poblaci√≥n\n"
            ". Preguntas de investigaci√≥n bien formuladas\n"
        )
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        return response.text
    except Exception as e:
        return f"Error al generar planteamiento: {e}"

def generar_objetivos_investigacion(texto_resumen, contexto_usuario):
    if not GENAI_AVAILABLE:
        return "Instala google-generativeai para usar esta funci√≥n."
    
    try:
        client = genai.Client()
        prompt = (
            f"Con base en la siguiente s√≠ntesis de literatura cient√≠fica y el contexto del investigador:\n{texto_resumen}\n\n"
            f"Considerando que el investigador desea enfocarse en: {contexto_usuario}\n"
            "Genera los objetivos de investigaci√≥n para un proyecto acad√©mico que incluyan:\n"
            "- Un objetivo general\n"
            "- Tres a cinco objetivos espec√≠ficos coherentes con el problema y la justificaci√≥n\n"
        )
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        return response.text
    except Exception as e:
        return f"Error al generar objetivos: {e}"

def sugerir_variables_operativas(texto_resumen, contexto_usuario):
    if not GENAI_AVAILABLE:
        return "Instala google-generativeai para usar esta funci√≥n."
    
    try:
        client = genai.Client()
        prompt = (
            f"Basado en esta s√≠ntesis de literatura cient√≠fica:\n{texto_resumen}\n\n"
            f"Considerando que el investigador trabaja en el contexto: {contexto_usuario}\n"
            "Genera una propuesta de variables de investigaci√≥n (dependientes, independientes, mediadoras, moderadoras) "
            "y sus definiciones operativas claras, espec√≠ficas y coherentes con el problema y objetivos de investigaci√≥n."
        )
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        return response.text
    except Exception as e:
        return f"Error al generar variables: {e}"

def generar_sugerencias_metodologicas(texto_resumen, contexto_usuario):
    if not GENAI_AVAILABLE:
        return "Instala google-generativeai para usar esta funci√≥n."
    
    try:
        client = genai.Client()
        prompt = (
            f"Considerando la siguiente s√≠ntesis de literatura cient√≠fica:\n{texto_resumen}\n\n"
            f"Y el contexto de investigaci√≥n: {contexto_usuario}\n"
            "Genera sugerencias detalladas sobre:\n"
            "- Tipo o enfoque metodol√≥gico (cuantitativo, cualitativo, mixto)\n"
            "- Dise√±o de investigaci√≥n apropiado\n"
            "- T√©cnicas e instrumentos de recolecci√≥n de datos recomendadas\n"
            "- Estrategias para el an√°lisis de datos\n"
            "Estas sugerencias deben ser coherentes con el planteamiento del problema y los objetivos de investigaci√≥n."
        )
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        return response.text
    except Exception as e:
        return f"Error al generar sugerencias metodol√≥gicas: {e}"

def generar_bibliografia(referencias, estilo="APA"):
    def formatear_cita(ref):
        autor = ref.get("autor", "Desconocido").strip()
        a√±o = ref.get("a√±o", "").strip() or "s.f."
        titulo = ref.get("titulo", "").strip()
        publicacion = ref.get("publicacion", "").strip()
        url = ref.get("url", "").strip()

        if estilo.upper() == "APA":
            partes = []
            partes.append(f"{autor} ({a√±o})")
            if titulo:
                partes.append(f"{titulo}.")
            if publicacion:
                partes.append(f"{publicacion}.")
            cita = " ".join(partes)
            if url:
                cita += f" Recuperado de {url}"
        elif estilo.upper() == "UPEL":
            partes = []
            partes.append(f"{autor}. ({a√±o}).")
            if titulo:
                partes.append(f"{titulo}.")
            if publicacion:
                partes.append(f"{publicacion}.")
            cita = " ".join(partes)
            if url:
                cita += f" Disponible en: {url}"
        else:
            cita = f"{autor}, {a√±o}, {titulo}"
        return " ".join(cita.split())

    bibliografia = [formatear_cita(ref) for ref in referencias]
    return "\n\n".join(bibliografia)

# FUNCI√ìN PRINCIPAL DE STREAMLIT
def main():
    # Configuraci√≥n de p√°gina
    st.set_page_config(
        page_title="Asistente de Investigaci√≥n Inteligente",
        page_icon="üî¨",
        layout="wide"
    )
    
    # Header principal con advertencias de dependencias
    st.markdown("""
    <div class="main-header" style="text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 20px;">
        <h1>üî¨ Asistente de Investigaci√≥n Inteligente</h1>
        <p>Chatbot mejorado con procesamiento avanzado de lenguaje natural</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Mostrar advertencias de dependencias
    if not all([BEAUTIFULSOUP_AVAILABLE, GENAI_AVAILABLE, DOCX_AVAILABLE, SEMANTIC_SCHOLAR_AVAILABLE]):
        st.warning("""
        ‚ö†Ô∏è **Algunas funcionalidades est√°n limitadas.** Para una experiencia completa, instala:
        ```
        pip install beautifulsoup4 google-generativeai python-docx semantic-scholar
        ```
        """)
    
    # Sidebar
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/2913/2913517.png", width=80)
        st.title("Configuraci√≥n")
        
        st.markdown("---")
        st.subheader("üîç B√∫squeda")
        max_results = st.slider("Resultados por base", 1, 10, 5)
        
        st.markdown("---")
        st.subheader("üì§ Exportaci√≥n")
        formato_exportacion = st.selectbox("Formato preferido", ["CSV", "DOCX", "TXT"])
        
        st.markdown("---")
        st.subheader("‚ÑπÔ∏è Informaci√≥n")
        st.info("""
        **Bases de datos:**
        - Semantic Scholar ‚úÖ
        - SciELO ‚úÖ
        
        **Funcionalidades MEJORADAS:**
        - Chatbot inteligente con NLP
        - Detecci√≥n autom√°tica de temas
        - Generaci√≥n contextualizada
        - Exportaci√≥n de resultados
        """)
    
    # Inicializar session state
    if 'articulos' not in st.session_state:
        st.session_state.articulos = []
    if 'agente' not in st.session_state:
        st.session_state.agente = AgenteConMemoria()
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'contexto_actual' not in st.session_state:
        st.session_state.contexto_actual = ""
    
    # Pesta√±as principales
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üè† Inicio", 
        "üîç B√∫squeda Acad√©mica", 
        "üìä Generar Proyecto", 
        "üí¨ Chat con Agente",
        "üìÖ Exportar Resultados"
    ])
    
    # Pesta√±a de Inicio
    with tab1:
        st.markdown("### üí° Bienvenido al Asistente de Investigaci√≥n Inteligente")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            ### üöÄ ¬øQu√© puedes hacer con esta herramienta?
            
            **üîç Chatbot Inteligente MEJORADO**
            - Procesamiento avanzado de lenguaje natural
            - Detecci√≥n autom√°tica de temas de investigaci√≥n
            - Generaci√≥n contextualizada de planteamientos
            - Respuestas espec√≠ficas y relevantes
            
            **üìö B√∫squeda Acad√©mica Integrada**
            - Buscar en Semantic Scholar (Internacional)
            - Buscar en SciELO (Am√©rica Latina)
            - Resultados en tiempo real
            - Filtrado por relevancia
            
            **ü§ñ An√°lisis con Inteligencia Artificial**
            - Res√∫menes autom√°ticos de literatura
            - Detecci√≥n de tendencias de investigaci√≥n
            - Identificaci√≥n de vac√≠os en la literatura
            - Sugerencias de l√≠neas de investigaci√≥n
            
            **üìã Desarrollo de Proyectos**
            - Generar planteamientos de problema
            - Definir objetivos de investigaci√≥n
            - Sugerir variables operativas
            - Proponer metodolog√≠as apropiadas
            """)
        
        with col2:
            st.markdown("""
            ### üéØ Comenzar es f√°cil:
            
            1. **Ve a la pesta√±a üí¨ Chat con Agente**
            2. **Escribe tu pregunta naturalmente**
            3. **El sistema detectar√° autom√°ticamente tu tema**
            4. **Recibe respuestas contextualizadas**
            
            ### üí¨ Ejemplos de preguntas:
            - *"Formula el planteamiento sobre competencias digitales en entornos automatizados"*
            - *"Genera objetivos para investigaci√≥n sobre IA en educaci√≥n"*
            - *"Sugiere metodolog√≠a para estudiar impacto de redes sociales"*
            
            ### üóÉÔ∏è Bases disponibles:
            ‚òë Semantic Scholar  
            ‚òë SciELO  
            ‚òë Acceso gratuito  
            """)
        
        st.markdown("---")
        st.subheader("üìä Estad√≠sticas de la sesi√≥n")
        col_stats1, col_stats2, col_stats3 = st.columns(3)
        with col_stats1:
            st.metric("Art√≠culos encontrados", len(st.session_state.articulos))
        with col_stats2:
            st.metric("Consultas al agente", len(st.session_state.agente.obtener_memoria()))
        with col_stats3:
            st.metric("Mensajes en chat", len(st.session_state.chat_history))
    
    # Pesta√±a de B√∫squeda Acad√©mica
    with tab2:
        st.markdown("### üîç B√∫squeda en Bases Acad√©micas")
        
        col_search1, col_search2 = st.columns([2, 1])
        
        with col_search1:
            consulta = st.text_input(
                "üîç Tema de investigaci√≥n:",
                placeholder="Ej: inteligencia artificial educaci√≥n secundaria",
                help="Describe tu tema de investigaci√≥n con palabras clave espec√≠ficas"
            )
        
        with col_search2:
            contexto = st.text_input(
                "üéØ Contexto espec√≠fico:",
                placeholder="Ej: an√°lisis de impacto en Venezuela",
                help="Especifica el contexto o enfoque particular"
            )
        
        # Selecci√≥n de bases de datos
        st.subheader("Selecciona las bases de datos:")
        col_db1, col_db2 = st.columns(2)
        
        with col_db1:
            usar_semantic = st.checkbox("Semantic Scholar", value=True, 
                                      disabled=not SEMANTIC_SCHOLAR_AVAILABLE,
                                      help="Art√≠culos en ingl√©s e internacionales")
        with col_db2:
            usar_scielo = st.checkbox("SciELO", value=True,
                                    disabled=not BEAUTIFULSOUP_AVAILABLE,
                                    help="Revistas cient√≠ficas de Am√©rica Latina")
        
        if st.button("üîç Ejecutar B√∫squeda Integral", type="primary", use_container_width=True):
            if not consulta:
                st.error("üìå Por favor ingresa un tema de investigaci√≥n")
            else:
                with st.spinner("üîç Buscando en bases acad√©micas..."):
                    # Ejecutar b√∫squedas
                    articulos_encontrados = []
                    
                    if usar_semantic and SEMANTIC_SCHOLAR_AVAILABLE:
                        with st.expander("üåê Semantic Scholar", expanded=True):
                            resultados_ss = buscar_semantic_scholar(consulta, max_results)
                            articulos_encontrados.extend(resultados_ss)
                            st.success(f"üìÑ Encontrados: {len(resultados_ss)} art√≠culos")
                    elif usar_semantic:
                        st.error("Semantic Scholar no est√° disponible")
                    
                    if usar_scielo and BEAUTIFULSOUP_AVAILABLE:
                        with st.expander("üåé SciELO", expanded=True):
                            resultados_scielo = buscar_scielo(consulta, max_results)
                            articulos_encontrados.extend(resultados_scielo)
                            st.success(f"üìÑ Encontrados: {len(resultados_scielo)} art√≠culos")
                    elif usar_scielo:
                        st.error("SciELO no est√° disponible - instala beautifulsoup4")
                    
                    # Guardar resultados
                    st.session_state.articulos = articulos_encontrados
                    st.session_state.consulta_actual = consulta
                    st.session_state.contexto_actual = contexto
                    
                    if articulos_encontrados:
                        st.success(f"‚úÖ B√∫squeda completada! Se encontraron {len(articulos_encontrados)} art√≠culos")
                        
                        # Generar y mostrar resumen con Gemini
                        with st.expander("ü§ñ Resumen y An√°lisis con IA", expanded=True):
                            texto_gemini = preparar_texto_para_gemini(articulos_encontrados)
                            if texto_gemini.strip():
                                if GENAI_AVAILABLE:
                                    resumen = resumir_articulos_con_gemini(texto_gemini)
                                    st.markdown(resumen)
                                    st.session_state.resumen_actual = resumen
                                else:
                                    st.info("""
                                    **Resumen no disponible** - Para usar esta funci√≥n:
                                    ```
                                    pip install google-generativeai
                                    ```
                                    """)
                            else:
                                st.warning("No se encontraron art√≠culos. Intenta con otros t√©rminos de b√∫squeda.")
                    else:
                        st.warning("No se encontraron art√≠culos con los criterios especificados.")
        
        # Mostrar resultados detallados
        if st.session_state.articulos:
            st.markdown("---")
            st.subheader("üìö Art√≠culos Encontrados")
            
            for i, articulo in enumerate(st.session_state.articulos):
                with st.expander(f"üìñ {articulo['titulo']}", key=f"art_{i}"):
                    col_info1, col_info2 = st.columns([3, 1])
                    
                    with col_info1:
                        st.write(f"**Autores:** {articulo['autor']}")
                        st.write(f"**A√±o:** {articulo['a√±o']}")
                        st.write(f"**Publicaci√≥n:** {articulo['publicacion']}")
                        st.write(f"**Fuente:** {articulo['fuente']}")
                    
                    with col_info2:
                        if articulo['url']:
                            st.markdown(f"[üîó Enlace al art√≠culo]({articulo['url']})")
                        else:
                            st.write("üîó Enlace no disponible")
    
    # Pesta√±a de Generar Proyecto
    with tab3:
        st.markdown("### üìä Generar Elementos de Investigaci√≥n")
        
        if not st.session_state.articulos:
            st.warning("‚ö†Ô∏è Primero realiza una b√∫squeda en la pesta√±a anterior para generar contenido.")
        else:
            col_gen1, col_gen2 = st.columns(2)
            
            with col_gen1:
                if st.button("üìù Generar Planteamiento del Problema", use_container_width=True,
                           disabled=not GENAI_AVAILABLE):
                    with st.spinner("Generando planteamiento del problema..."):
                        if hasattr(st.session_state, 'resumen_actual'):
                            planteamiento = generar_planteamiento_problema(
                                st.session_state.resumen_actual,
                                st.session_state.contexto_actual
                            )
                            st.session_state.planteamiento = planteamiento
                            st.markdown(planteamiento)
                        else:
                            st.error("Primero genera un resumen en la pesta√±a de B√∫squeda")
                if not GENAI_AVAILABLE:
                    st.info("Instala google-generativeai para usar esta funci√≥n")
            
            with col_gen2:
                if st.button("üéØ Generar Objetivos de Investigaci√≥n", use_container_width=True,
                           disabled=not GENAI_AVAILABLE):
                    with st.spinner("Generando objetivos de investigaci√≥n..."):
                        if hasattr(st.session_state, 'resumen_actual'):
                            objetivos = generar_objetivos_investigacion(
                                st.session_state.resumen_actual,
                                st.session_state.contexto_actual
                            )
                            st.session_state.objetivos = objetivos
                            st.markdown(objetivos)
                        else:
                            st.error("Primero genera un resumen en la pesta√±a de B√∫squeda")
                if not GENAI_AVAILABLE:
                    st.info("Instala google-generativeai para usar esta funci√≥n")
            
            st.markdown("---")
            col_gen3, col_gen4 = st.columns(2)
            
            with col_gen3:
                if st.button("üìä Sugerir Variables Operativas", use_container_width=True,
                           disabled=not GENAI_AVAILABLE):
                    with st.spinner("Generando variables operativas..."):
                        if hasattr(st.session_state, 'resumen_actual'):
                            variables = sugerir_variables_operativas(
                                st.session_state.resumen_actual,
                                st.session_state.contexto_actual
                            )
                            st.session_state.variables = variables
                            st.markdown(variables)
                        else:
                            st.error("Primero genera un resumen en la pesta√±a de B√∫squeda")
                if not GENAI_AVAILABLE:
                    st.info("Instala google-generativeai para usar esta funci√≥n")
            
            with col_gen4:
                if st.button("üî¨ Generar Sugerencias Metodol√≥gicas", use_container_width=True,
                           disabled=not GENAI_AVAILABLE):
                    with st.spinner("Generando sugerencias metodol√≥gicas..."):
                        if hasattr(st.session_state, 'resumen_actual'):
                            metodologia = generar_sugerencias_metodologicas(
                                st.session_state.resumen_actual,
                                st.session_state.contexto_actual
                            )
                            st.session_state.metodologia = metodologia
                            st.markdown(metodologia)
                        else:
                            st.error("Primero genera un resumen en la pesta√±a de B√∫squeda")
                if not GENAI_AVAILABLE:
                    st.info("Instala google-generativeai para usar esta funci√≥n")
    
    # Pesta√±a de Chat con Agente - COMPLETAMENTE REDISE√ëADA
    with tab4:
        st.markdown("### üí¨ Chat Inteligente con el Agente de Investigaci√≥n")
        
        st.info("""
        üéØ **Pregunta naturalmente sobre:**
        - Planteamientos de problemas de investigaci√≥n
        - Objetivos y metodolog√≠as
        - An√°lisis de datos y variables
        - Redacci√≥n acad√©mica y referencias
        - Dise√±o de instrumentos de investigaci√≥n
        
        üí° **Ejemplo:** *"Formula el planteamiento del problema sobre competencias digitales en entornos automatizados"*
        """)
        
        # Configuraci√≥n de contexto
        st.session_state.contexto_actual = st.text_input(
            "üéØ Contexto de investigaci√≥n (opcional):",
            placeholder="Ej: educaci√≥n superior en Latinoam√©rica",
            help="Proporciona contexto para respuestas m√°s precisas"
        )
        
        # Mostrar historial
