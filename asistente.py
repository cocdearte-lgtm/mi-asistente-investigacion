import os
import streamlit as st
from langchain.agents import initialize_agent, Tool, AgentType
from langchain_community.utilities import SerpAPIWrapper
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
import numpy as np
import re
from datetime import date
from docx import Document
from docx.shared import Pt, Inches
from io import BytesIO
import requests

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Agente de IA para Investigaci√≥n Acad√©mica",
    page_icon="üìö",
    layout="wide"
)

# Inicializar el modelo OpenAI
try:
    llm = ChatOpenAI(
        model="gpt-4",
        temperature=0.7,
        openai_api_key=st.secrets.get("OPENAI_API_KEY", "")
    )
    st.write("‚úÖ Conexi√≥n con OpenAI exitosa")
except Exception as e:
    st.error(f"‚ùå Error al conectar con OpenAI: {str(e)}")
    st.stop()

# Configurar la herramienta de b√∫squeda general
try:
    search = SerpAPIWrapper()
    search_tool = Tool(
        name="Academic_Search",
        func=lambda x: "\n".join([f"{i+1}. {item.strip('[]')}" for i, item in enumerate(search.run(x+" after:2023").split(","))]) if "a√±o" in x.lower() else "\n".join([f"{i+1}. {item.strip('[]')}" for i, item in enumerate(search.run(x).split(","))]),
        description="Busca en Google Scholar art√≠culos acad√©micos. A√±ade 'a√±o' para filtrar desde 2023."
    )
    st.write("‚úÖ Herramienta de b√∫squeda general configurada")
except Exception as e:
    st.error(f"‚ùå Error al configurar b√∫squeda general: {str(e)}")
    st.stop()

# Configurar la herramienta de b√∫squeda UPEL
try:
    upel_search = SerpAPIWrapper()
    upel_search_tool = Tool(
        name="UPEL_Search",
        func=lambda x: "\n".join([f"{i+1}. {item.strip('[]')}" for i, item in enumerate(upel_search.run(x+" site:*.upel.edu.ve").split(","))]),
        description="Busca art√≠culos acad√©micos relacionados con la UPEL (Universidad Pedag√≥gica Experimental Libertador)."
    )
    st.write("‚úÖ Herramienta de b√∫squeda UPEL configurada")
except Exception as e:
    st.error(f"‚ùå Error al configurar b√∫squeda UPEL: {str(e)}")
    st.stop()

# Configurar la herramienta matem√°tica
def math_calculator(expression: str) -> str:
    """Calcula expresiones matem√°ticas, incluyendo media y desviaci√≥n est√°ndar"""
    try:
        if 'media' in expression.lower() or 'm√©dia' in expression.lower() or 'moyenne' in expression.lower():
            nums = eval(expression.split('de')[-1].strip() if 'de' in expression else expression.split('of')[-1].strip() if 'of' in expression else expression.split('moyenne')[-1].strip())
            return str(np.mean(nums))
        elif 'desviaci√≥n est√°ndar' in expression.lower() or 'desvio padr√£o' in expression.lower() or '√©cart-type' in expression.lower():
            nums = eval(expression.split('de')[-1].strip() if 'de' in expression else expression.split('of')[-1].strip() if 'of' in expression else expression.split('√©cart-type')[-1].strip())
            return str(np.std(nums))
        else:
            return str(eval(expression))
    except Exception as e:
        return f"Error: {str(e)}"

# Configurar la herramienta de resumen simple
def summarize_article(text: str, language: str = "Espa√±ol") -> str:
    """Genera un resumen breve del texto proporcionado en el idioma especificado."""
    try:
        prompt_templates = {
            "Espa√±ol": f"Resume el siguiente texto en no m√°s de 50 palabras: {text}",
            "Ingl√©s": f"Summarize the following text in no more than 50 words: {text}",
            "Portugu√©s": f"Resuma o seguinte texto em no m√°ximo 50 palavras: {text}",
            "Franc√©s": f"R√©sumez le texte suivant en 50 mots maximum : {text}"
        }
        summary = llm.invoke(prompt_templates[language])
        return summary.content.strip()
    except Exception as e:
        return f"Error al resumir: {str(e)}"

# Configurar la herramienta de resumen estructurado
def generate_structured_summary(query: str) -> str:
    """Genera un resumen estructurado (Introducci√≥n, Objetivos, Metodolog√≠a, Resultados, Conclusiones) en el idioma especificado."""
    try:
        language = st.session_state.get("language", "Espa√±ol")
        text_match = re.search(r"para el primero", query.lower())
        search_query = query + (" site:*.upel.edu.ve" if "repositorio upel" in query.lower() else " after:2023" if "a√±o" in query.lower() else "")
        
        search_results = upel_search.run(search_query) if "repositorio upel" in query.lower() else search.run(search_query)
        article = search_results.split("', ")[0].strip('[]') if text_match else query

        prompt_templates = {
            "Espa√±ol": f"Genera un resumen estructurado del siguiente art√≠culo en espa√±ol, con las secciones Introducci√≥n, Objetivos, Metodolog√≠a, Resultados y Conclusiones, con un m√°ximo de 150 palabras en total: {article}",
            "Ingl√©s": f"Generate a structured summary of the following article in English, with sections Introduction, Objectives, Methodology, Results, and Conclusions, with a maximum of 150 words in total: {article}",
            "Portugu√©s": f"Gere um resumo estruturado do seguinte artigo em portugu√™s, com as se√ß√µes Introdu√ß√£o, Objetivos, Metodologia, Resultados e Conclus√µes, com um m√°ximo de 150 palavras no total: {article}",
            "Franc√©s": f"G√©n√©rez un r√©sum√© structur√© de l'article suivant en fran√ßais, avec les sections Introduction, Objectifs, M√©thodologie, R√©sultats et Conclusions, avec un maximum de 150 mots au total : {article}"
        }
        
        summary = llm.invoke(prompt_templates[language])
        return summary.content.strip()
    except Exception as e:
        return f"Error al generar resumen estructurado: {str(e)}"

# Configurar la herramienta de citas APA
def generate_apa_citation(text: str, language: str = "Espa√±ol") -> str:
    """Genera una cita en formato APA en el idioma especificado."""
    try:
        title_match = re.search(r"^(.*?)\\.", text)
        title = title_match.group(1) if title_match else "T√≠tulo no disponible"
        
        authors_match = re.search(r"\\s*([A-Za-z\\s\\.]+)\\.", text)
        authors = authors_match.group(1) if authors_match else "Autor no disponible"
        
        year_match = re.search(r"\((\d{4})\)", text)
        year = year_match.group(1) if year_match else "s.f."
        
        citation_templates = {
            "Espa√±ol": f"{authors}. ({year}). {title}. Recuperado de Google Scholar.",
            "Ingl√©s": f"{authors}. ({year}). {title}. Retrieved from Google Scholar.",
            "Portugu√©s": f"{authors}. ({year}). {title}. Recuperado do Google Scholar.",
            "Franc√©s": f"{authors}. ({year}). {title}. R√©cup√©r√© de Google Scholar."
        }
        
        return citation_templates[language]
    except Exception as e:
        return f"Error al generar cita APA: {str(e)}"

# Configurar la herramienta de citas UPEL
def generate_upel_citation(text: str, work_type: str = "Tesis", language: str = "Espa√±ol") -> str:
    """Genera una cita seg√∫n el Manual de Trabajo de Grado, Especializaci√≥n, Maestr√≠a y Tesis Doctorales de la UPEL."""
    try:
        today = date.today().strftime("%d/%m/%Y")
        title_match = re.search(r"^(.*?)\\.", text)
        title = title_match.group(1) if title_match else "T√≠tulo no disponible"
        
        authors_match = re.search(r"\\s*([A-Za-z,\\s\\.]+)\\.", text)
        authors = authors_match.group(1) if authors_match else "Autor no disponible"
        
        year_match = re.search(r"\((\d{4})\)", text)
        year = year_match.group(1) if year_match else "s.f."
        
        citation_templates = {
            "Espa√±ol": f"{authors}. ({year}). {title}. {work_type}. Universidad Pedag√≥gica Experimental Libertador. Recuperado el {today} de Google Scholar.",
            "Ingl√©s": f"{authors}. ({year}). {title}. {work_type}. Universidad Pedag√≥gica Experimental Libertador. Retrieved on {today} from Google Scholar.",
            "Portugu√©s": f"{authors}. ({year}). {title}. {work_type}. Universidad Pedag√≥gica Experimental Libertador. Recuperado em {today} do Google Scholar.",
            "Franc√©s": f"{authors}. ({year}). {title}. {work_type}. Universidad Pedag√≥gica Experimental Libertador. R√©cup√©r√© le {today} de Google Scholar."
        }
        
        return citation_templates[language]
    except Exception as e:
        return f"Error al generar cita UPEL: {str(e)}"

# Herramienta de citas UPEL con l√≥gica para tipo de trabajo
def generate_upel_citation_tool(query: str) -> str:
    """Herramienta que genera una cita UPEL, seleccionando el tipo de trabajo e idioma."""
    try:
        work_type = st.session_state.get("upel_work_type", "Tesis")
        language = st.session_state.get("language", "Espa√±ol")
        
        if "trabajo de grado" in query.lower():
            work_type = "Trabajo de Grado"
        elif "tesis de maestr√≠a" in query.lower():
            work_type = "Tesis de Maestr√≠a"
        elif "tesis doctoral" in query.lower():
            work_type = "Tesis Doctoral"
            
        text_match = re.search(r"para el primero", query.lower())
        search_query = query + (" site:*.upel.edu.ve" if "repositorio upel" in query.lower() else " after:2023" if "a√±o" in query.lower() else "")
        
        search_results = upel_search.run(search_query) if "repositorio upel" in query.lower() else search.run(search_query)
        first_result = search_results.split("', ")[0].strip('[]') if text_match else query
        
        return generate_upel_citation(first_result, work_type, language)
    except Exception as e:
        return f"Error al generar cita UPEL: {str(e)}"

# Herramienta para generar bibliograf√≠a
def generate_bibliography(query: str) -> str:
    """Genera una lista de referencias ordenada alfab√©ticamente en el formato especificado."""
    try:
        language = st.session_state.get("language", "Espa√±ol")
        citation_format = st.session_state.get("citation_format", "APA")
        work_type = st.session_state.get("upel_work_type", "Tesis") if citation_format == "UPEL" else None
        
        search_query = query + (" site:*.upel.edu.ve" if "repositorio upel" in query.lower() else " after:2023" if "a√±o" in query.lower() else "")
        search_results = upel_search.run(search_query) if "repositorio upel" in query.lower() else search.run(search_query)
        
        articles = [item.strip('[]') for item in search_results.split("', ")[:5]]
        citations = []
        
        for article in articles:
            if citation_format == "APA":
                citation = generate_apa_citation(article, language)
            else:
                citation = generate_upel_citation(article, work_type, language)
            
            if "Error" not in citation:
                citations.append(citation)
        
        citations.sort()
        
        bibliography_title = {
            "Espa√±ol": "Referencias",
            "Ingl√©s": "References",
            "Portugu√©s": "Refer√™ncias",
            "Franc√©s": "R√©f√©rences"
        }[language]
        
        return f"{bibliography_title}:\n" + "\n".join(citations) if citations else "No se encontraron art√≠culos v√°lidos."
    except Exception as e:
        return f"Error al generar bibliograf√≠a: {str(e)}"

# Herramienta para generar tabla comparativa
def generate_comparison_table(query: str) -> str:
    """Genera una tabla comparativa de hasta 3 art√≠culos con Autor, T√≠tulo, A√±o, Metodolog√≠a, Hallazgos."""
    language = st.session_state.get("language", "Espa√±ol")
    
    search_query = query + (" site:*.upel.edu.ve" if "repositorio upel" in query.lower() else " after:2023" if "a√±o" in query.lower() else "")
    search_results = upel_search.run(search_query) if "repositorio upel" in query.lower() else search.run(search_query)
    
    articles = [item.strip('[]') for item in search_results.split("', ")[:3]]
    table_rows = []
    
    for article in articles:
        title_match = re.search(r"^(.*?)\\.", article)
        title = title_match.group(1) if title_match else "T√≠tulo no disponible"
        
        authors_match = re.search(r"\\.\\s*([A-Za-z,\\s\\.]+)\\.", article)
        authors = authors_match.group(1) if authors_match else "Autor no disponible"
        
        year_match = re.search(r"\((\d{4})\)", article)
        year = year_match.group(1) if year_match else "s.f."
        
        prompt_templates = {
            "Espa√±ol": f"Describe brevemente la metodolog√≠a (m√°ximo 20 palabras) y hallazgos principales (m√°ximo 30 palabras) del art√≠culo: {article}",
            "Ingl√©s": f"Briefly describe the methodology (max 20 words) and main findings (max 30 words) of the article: {article}",
            "Portugu√©s": f"Descreva brevemente a metodologia (m√°ximo 20 palavras) e os principais achados (m√°ximo 30 palavras) do artigo: {article}",
            "Franc√©s": f"D√©crivez bri√®vement la m√©thodologie (max 20 mots) et les principaux r√©sultats (max 30 mots) de l'article : {article}"
        }
        
        analysis = llm.invoke(prompt_templates[language]).content.strip().split("\n")
        methodology = analysis[0] if len(analysis) > 0 else "Metodolog√≠a no disponible"
        findings = analysis[1] if len(analysis) > 1 else "Hallazgos no disponibles"
        
        table_rows.append([authors, title, year, methodology, findings])
    
    headers = {
        "Espa√±ol": ["Autor", "T√≠tulo", "A√±o", "Metodolog√≠a", "Hallazgos Principales"], 
        "Ingl√©s": ["Author", "Title", "Year", "Methodology", "Main Findings"], 
        "Portugu√©s": ["Autor", "T√≠tulo", "Ano", "Metodologia", "Principais Achados"], 
        "Franc√©s": ["Auteur", "Titre", "Ann√©e", "M√©thodologie", "R√©sultats Principaux"] 
    }[language]
    
    table = f"{headers[0]} | {headers[1]} | {headers[2]} | {headers[3]} | {headers[4]}\n"
    table += "--- | --- | --- | --- | ---\n"
    
    for row in table_rows:
        table += f"{row[0]} | {row[1]} | {row[2]} | {row[3]} | {row[4]}\n"
    
    table_title = {
        "Espa√±ol": "Tabla Comparativa",
        "Ingl√©s": "Comparison Table",
        "Portugu√©s": "Tabela Comparativa",
        "Franc√©s": "Tableau Comparatif"
    }[language]
    
    return f"{table_title}:\n{table}"

# Herramienta para generar esquema de investigaci√≥n
def generate_research_outline(query: str) -> str:
    """Genera un esquema de investigaci√≥n con Introducci√≥n, Marco Te√≥rico, Metodolog√≠a, Resultados Esperados, Conclusiones."""
    language = st.session_state.get("language", "Espa√±ol")
    
    prompt_templates = {
        "Espa√±ol": f"Genera un esquema de investigaci√≥n en espa√±ol para un estudio sobre {query}, con las secciones Introducci√≥n, Marco Te√≥rico, Metodolog√≠a, Resultados Esperados y Conclusiones, con un m√°ximo de 200 palabras en total.",
        "Ingl√©s": f"Generate a research outline in English for a study on {query}, with sections Introduction, Theoretical Framework, Methodology, Expected Results, and Conclusions, with a maximum of 200 words in total.",
        "Portugu√©s": f"Gere um esbo√ßo de pesquisa em portugu√™s para um estudo sobre {query}, com as se√ß√µes Introdu√ß√£o, Quadro Te√≥rico, Metodologia, Resultados Esperados e Conclus√µes, com um m√°ximo de 200 palavras no total.",
        "Franc√©s": f"G√©n√©rez un plan de recherche en fran√ßais pour une √©tude sur {query}, avec les sections Introduction, Cadre Th√©orique, M√©thodologie, R√©sultats Attendus et Conclusions, avec un maximum de 200 mots au total."
    }
    
    outline = llm.invoke(prompt_templates[language]).content.strip()
    
    outline_title = {
        "Espa√±ol": "Esquema de Investigaci√≥n",
        "Ingl√©s": "Research Outline",
        "Portugu√©s": "Esbo√ßo de Pesquisa",
        "Franc√©s": "Plan de Recherche"
    }[language]
    
    return f"{outline_title}:\n{outline}"

# Herramienta para generar propuestas de t√≠tulos
def generate_research_titles(query: str) -> str:
    """Genera hasta 5 propuestas de t√≠tulos acad√©micos para un tema de investigaci√≥n."""
    language = st.session_state.get("language", "Espa√±ol")
    
    search_query = query + (" site:*.upel.edu.ve" if "repositorio upel" in query.lower() else " after:2023" if "a√±o" in query.lower() else "")
    search_results = upel_search.run(search_query) if "repositorio upel" in query.lower() else search.run(search_query)
    
    context = "\n".join([item.strip('[]') for item in search_results.split("', ")[:3]])
    
    prompt_templates = {
        "Espa√±ol": f"Bas√°ndote en el siguiente contexto, genera 5 propuestas de t√≠tulos acad√©micos en espa√±ol para un estudio sobre {query}, cada uno con un m√°ximo de 20 palabras:\nContexto: {context}",
        "Ingl√©s": f"Based on the following context, generate 5 academic title proposals in English for a study on {query}, each up to 20 words:\nContext: {context}",
        "Portugu√©s": f"Com base no seguinte contexto, gere 5 propostas de t√≠tulos acad√©micos em portugu√™s para um estudo sobre {query}, cada um com at√© 20 palavras:\nContexto: {context}",
        "Franc√©s": f"En vous basant sur le contexte suivant, g√©n√©rez 5 propositions de titres acad√©miques en fran√ßais pour une √©tude sur {query}, chacun jusqu'√† 20 mots :\nContexte : {context}"
    }
    
    titles = llm.invoke(prompt_templates[language]).content.strip()
    titles_list = [line.strip() for line in titles.split("\n") if line.strip()][:5]
    titles_formatted = "\n".join([f"{i+1}. {title}" for i, title in enumerate(titles_list)])
    
    titles_title = {
        "Espa√±ol": "Propuestas de T√≠tulos de Investigaci√≥n",
        "Ingl√©s": "Research Title Proposals",
        "Portugu√©s": "Propostas de T√≠tulos de Pesquisa",
        "Franc√©s": "Propositions de Titres de Recherche"
    }[language]
    
    return f"{titles_title}:\n{titles_formatted}"

# Herramienta para generar mapa conceptual
def generate_concept_map(query: str) -> str:
    """Genera un mapa conceptual en formato texto con nodos principales y secundarios."""
    language = st.session_state.get("language", "Espa√±ol")
    
    search_query = query + (" site:*.upel.edu.ve" if "repositorio upel" in query.lower() else " after:2023" if "a√±o" in query.lower() else "")
    search_results = upel_search.run(search_query) if "repositorio upel" in query.lower() else search.run(search_query)
    
    context = "\n".join([item.strip('[]') for item in search_results.split("', ")[:3]])
    
    prompt_templates = {
        "Espa√±ol": f"Bas√°ndote en el siguiente contexto, genera un mapa conceptual en espa√±ol para un estudio sobre {query}, en formato de lista jer√°rquica con 3 nodos principales y hasta 3 nodos secundarios por cada uno, con un m√°ximo de 150 palabras en total:\nContexto: {context}",
        "Ingl√©s": f"Based on the following context, generate a concept map in English for a study on {query}, in a hierarchical list format with 3 main nodes and up to 3 secondary nodes each, with a maximum of 150 words in total:\nContext: {context}",
        "Portugu√©s": f"Com base no seguinte contexto, gere um mapa conceitual em portugu√™s para um estudo sobre {query}, em formato de lista hier√°rquica com 3 n√≥s principais e at√© 3 n√≥s secund√°rios por cada um, com um m√°ximo de 150 palavras no total:\nContexto: {context}",
        "Franc√©s": f"En vous basant sur le contexte suivant, g√©n√©rez une carte conceptuelle en fran√ßais pour une √©tude sur {query}, sous forme de liste hi√©rarchique avec 3 n≈ìuds principaux et jusqu'√† 3 n≈ìuds secondaires chacun, avec un maximum de 150 mots au total : \nContexte : {context}"
    }
    
    concept_map = llm.invoke(prompt_templates[language]).content.strip()
    
    concept_map_title = {
        "Espa√±ol": "Mapa Conceptual",
        "Ingl√©s": "Concept Map",
        "Portugu√©s": "Mapa Conceitual",
        "Franc√©s": "Carte Conceptuelle"
    }[language]
    
    return f"{concept_map_title}:\n{concept_map}"

# Herramienta para generar preguntas de investigaci√≥n
def generate_research_questions(query: str) -> str:
    """Genera hasta 5 preguntas de investigaci√≥n para un tema de investigaci√≥n."""
    language = st.session_state.get("language", "Espa√±ol")
    
    search_query = query + (" site:*.upel.edu.ve" if "repositorio upel" in query.lower() else " after:2023" if "a√±o" in query.lower() else "")
    search_results = upel_search.run(search_query) if "repositorio upel" in query.lower() else search.run(search_query)
    
    context = "\n".join([item.strip('[]') for item in search_results.split("', ")[:3]])
    
    prompt_templates = {
        "Espa√±ol": f"Bas√°ndote en el siguiente contexto, genera 5 preguntas de investigaci√≥n en espa√±ol para un estudio sobre {query}, cada una con un m√°ximo de 20 palabras:\nContexto: {context}",
        "Ingl√©s": f"Based on the following context, generate 5 research questions in English for a study on {query}, each up to 20 words:\nContext: {context}",
        "Portugu√©s": f"Com base no seguinte contexto, gere 5 perguntas de pesquisa em portugu√™s para um estudo sobre {query}, cada uma com at√© 20 palavras:\nContexto: {context}",
        "Franc√©s": f"En vous basant sur le contexte suivant, g√©n√©rez 5 questions de recherche en fran√ßais pour une √©tude sur {query}, chacune jusqu'√† 20 mots :\nContexte : {context}"
    }
    
    questions = llm.invoke(prompt_templates[language]).content.strip()
    questions_list = [line.strip() for line in questions.split("\n") if line.strip()][:5]
    questions_formatted = "\n".join([f"{i+1}. {question}" for i, question in enumerate(questions_list)])
    
    questions_title = {
        "Espa√±ol": "Preguntas de Investigaci√≥n",
        "Ingl√©s": "Research Questions",
        "Portugu√©s": "Perguntas de Pesquisa",
        "Franc√©s": "Questions de Recherche"
    }[language]
    
    return f"{questions_title}:\n{questions_formatted}"

# Herramienta para generar objetivos de investigaci√≥n
def generate_research_objectives(query: str) -> str:
    """Genera un objetivo general y hasta 3 objetivos espec√≠ficos para un tema de investigaci√≥n."""
    language = st.session_state.get("language", "Espa√±ol")
    
    search_query = query + (" site:*.upel.edu.ve" if "repositorio upel" in query.lower() else " after:2023" if "a√±o" in query.lower() else "")
    search_results = upel_search.run(search_query) if "repositorio upel" in query.lower() else search.run(search_query)
    
    context = "\n".join([item.strip('[]') for item in search_results.split("', ")[:3]])
    
    prompt_templates = {
        "Espa√±ol": f"Bas√°ndote en el siguiente contexto, genera un objetivo general y 3 objetivos espec√≠ficos en espa√±ol para un estudio sobre {query}, cada uno con un m√°ximo de 20 palabras:\nContexto: {context}",
        "Ingl√©s": f"Based on the following context, generate one general objective and 3 specific objectives in English for a study on {query}, each up to 20 words:\nContext: {context}",
        "Portugu√©s": f"Com base no seguinte contexto, gere um objetivo geral e 3 objetivos espec√≠ficos em portugu√™s para um estudio sobre {query}, cada um com at√© 20 palavras:\nContexto: {context}",
        "Franc√©s": f"En vous basant sur le contexte suivant, g√©n√©rez un objectif g√©n√©ral et 3 objectifs sp√©cifiques en fran√ßais pour une √©tude sur {query}, chacun jusqu'√† 20 mots :\nContexte : {context}"
    }
    
    objectives = llm.invoke(prompt_templates[language]).content.strip()
    objectives_list = [line.strip() for line in objectives.split("\n") if line.strip()][:4]
    
    objectives_formatted = ""
    if objectives_list:
        if language == "Espa√±ol":
            objectives_formatted += f"Objetivo General:\n{objectives_list[0]}\n\nObjetivos Espec√≠ficos:\n"
        elif language == "Ingl√©s":
            objectives_formatted += f"General Objective:\n{objectives_list[0]}\n\nSpecific Objectives:\n"
        elif language == "Portugu√©s":
            objectives_formatted += f"Objetivo Geral:\n{objectives_list[0]}\n\nObjetivos Espec√≠ficos:\n"
        else:  # Franc√©s
            objectives_formatted += f"Objectif G√©n√©ral:\n{objectives_list[0]}\n\nObjectifs Sp√©cifiques:\n"
        
        objectives_formatted += "\n".join([f"{i}. {obj}" for i, obj in enumerate(objectives_list[1:], 1)])
    
    objectives_title = {
        "Espa√±ol": "Objetivos de Investigaci√≥n",
        "Ingl√©s": "Research Objectives",
        "Portugu√©s": "Objetivos de Pesquisa",
        "Franc√©s": "Objectifs de Recherche"
    }[language]
    
    return f"{objectives_title}:\n{objectives_formatted}"

# Generar documento Word
def generate_word_document(content: str, language: str = "Espa√±ol", is_summary: bool = False, 
                         is_table: bool = False, is_outline: bool = False, is_titles: bool = False, 
                         is_concept_map: bool = False, is_questions: bool = False, 
                         is_objectives: bool = False) -> BytesIO:
    """Genera un documento Word con el contenido en formato acad√©mico."""
    doc = Document()
    sections = doc.sections
    for section in sections:
        section.left_margin = Inches(1)
        section.right_margin = Inches(1)
        section.top_margin = Inches(1)
        section.bottom_margin = Inches(1)
    
    title_texts = {
        "Espa√±ol": ("Objetivos de Investigaci√≥n" if is_objectives else
                   "Preguntas de Investigaci√≥n" if is_questions else
                   "Mapa Conceptual" if is_concept_map else
                   "Propuestas de T√≠tulos de Investigaci√≥n" if is_titles else
                   "Esquema de Investigaci√≥n" if is_outline else
                   "Tabla Comparativa" if is_table else
                   "Resumen Estructurado" if is_summary else
                   ("Referencias" if "\n" in content and not content.startswith("Autor |") else "Cita Generada")),
        "Ingl√©s": ("Research Objectives" if is_objectives else
                  "Research Questions" if is_questions else
                  "Concept Map" if is_concept_map else
                  "Research Title Proposals" if is_titles else
                  "Research Outline" if is_outline else
                  "Comparison Table" if is_table else
                  "Structured Summary" if is_summary else
                  ("References" if "\n" in content and not content.startswith("Author |") else "Generated Citation")),
        "Portugu√©s": ("Objetivos de Pesquisa" if is_objectives else
                     "Perguntas de Pesquisa" if is_questions else
                     "Mapa Conceitual" if is_concept_map else
                     "Propostas de T√≠tulos de Pesquisa" if is_titles else
                     "Esbo√ßo de Pesquisa" if is_outline else
                     "Tabela Comparativa" if is_table else
                     "Resumo Estruturado" if is_summary else
                     ("Refer√™ncias" if "\n" in content and not content.startswith("Autor |") else "Cita√ß√£o Gerada")),
        "Franc√©s": ("Objectifs de Recherche" if is_objectives else
                   "Questions de Recherche" if is_questions else
                   "Carte Conceptuelle" if is_concept_map else
                   "Propositions de Titres de Recherche" if is_titles else
                   "Plan de Recherche" if is_outline else
                   "Tableau Comparatif" if is_table else
                   "R√©sum√© Structur√©" if is_summary else
                   ("R√©f√©rences" if "\n" in content and not content.startswith("Auteur |") else "Citation G√©n√©r√©e"))
    }
    
    title = doc.add_heading(title_texts[language], level=1)
    title.style.font.name = "Times New Roman"
    title.style.font.size = Pt(12)

    if is_table:
        lines = content.split("\n")[1:]
        headers = [h.strip() for h in lines[0].split("|")]
        rows = [[cell.strip() for cell in line.split("|")] for line in lines[2:] if line.strip()]
        
        table = doc.add_table(rows=len(rows) + 1, cols=len(headers))
        table.style = "Table Grid"
        
        for i, header in enumerate(headers):
            cell = table.cell(0, i)
            cell.text = header
            cell.paragraphs[0].style.font.name = "Times New Roman"
            cell.paragraphs[0].style.font.size = Pt(12)
            cell.paragraphs[0].style.font.bold = True
        
        for i, row in enumerate(rows):
            for j, cell_content in enumerate(row):
                cell = table.cell(i + 1, j)
                cell.text = cell_content
                cell.paragraphs[0].style.font.name = "Times New Roman"
                cell.paragraphs[0].style.font.size = Pt(12)
    else:
        for line in content.split("\n"):
            p = doc.add_paragraph(line)
            p.style.font.name = "Times New Roman"
            p.style.font.size = Pt(12)
            p.paragraph_format.line_spacing = 1.5
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# Definir todas las herramientas
tools = [
    search_tool,
    upel_search_tool,
    Tool(
        name="Math_Calculator",
        func=math_calculator,
        description="Calcula expresiones matem√°ticas, incluyendo media y desviaci√≥n est√°ndar."
    ),
    Tool(
        name="Summarize_Article",
        func=lambda x: summarize_article(x, st.session_state.get("language", "Espa√±ol")),
        description="Genera un resumen breve de un texto o art√≠culo en el idioma seleccionado."
    ),
    Tool(
        name="Generate_Structured_Summary",
        func=generate_structured_summary,
        description="Genera un resumen estructurado (Introducci√≥n, Objetivos, Metodolog√≠a, Resultados, Conclusiones) de un art√≠culo en el idioma seleccionado."
    ),
    Tool(
        name="Generate_APA_Citation",
        func=lambda x: generate_apa_citation(x, st.session_state.get("language", "Espa√±ol")),
        description="Genera una cita en formato APA en el idioma seleccionado."
    ),
    Tool(
        name="Generate_UPEL_Citation",
        func=generate_upel_citation_tool,
        description="Genera una cita seg√∫n el Manual de Trabajo de Grado, Especializaci√≥n, Maestr√≠a y Tesis Doctorales de la UPEL, usando el tipo de trabajo e idioma seleccionados."
    ),
    Tool(
        name="Generate_Bibliography",
        func=generate_bibliography,
        description="Genera una lista de referencias ordenada alfab√©ticamente en formato APA o UPEL."
    ),
    Tool(
        name="Generate_Comparison_Table",
        func=generate_comparison_table,
        description="Genera una tabla comparativa de hasta 3 art√≠culos con Autor, T√≠tulo, A√±o, Metodolog√≠a y Hallazgos Principales."
    ),
    Tool(
        name="Generate_Research_Outline",
        func=generate_research_outline,
        description="Genera un esquema de investigaci√≥n con Introducci√≥n, Marco Te√≥rico, Metodolog√≠a, Resultados Esperados y Conclusiones."
    ),
    Tool(
        name="Generate_Research_Titles",
        func=generate_research_titles,
        description="Genera hasta 5 propuestas de t√≠tulos acad√©micos para un tema de investigaci√≥n."
    ),
    Tool(
        name="Generate_Concept_Map",
        func=generate_concept_map,
        description="Genera un mapa conceptual en formato texto con nodos principales y secundarios para un tema de investigaci√≥n."
    ),
    Tool(
        name="Generate_Research_Questions",
        func=generate_research_questions,
        description="Genera hasta 5 preguntas de investigaci√≥n para un tema de investigaci√≥n."
    ),
    Tool(
        name="Generate_Research_Objectives",
        func=generate_research_objectives,
        description="Genera un objetivo general y hasta 3 objetivos espec√≠ficos para un tema de investigaci√≥n."
    )
]

# Inicializar el agente con memoria
try:
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    agent = initialize_agent(
        tools=tools,
        llm=llm,
        agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True,
        memory=memory,
        handle_parsing_errors=True
    )
    st.write("‚úÖ Agente inicializado correctamente")
except Exception as e:
    st.error(f"‚ùå Error al inicializar el agente: {str(e)}")
    st.stop()

# Interfaz de chat mejorada
st.title("ü§ñ Agente de IA para Investigaci√≥n Acad√©mica")
st.markdown("---")

# Configuraci√≥n en sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥n")
    
    search_type = st.selectbox("Tipo de b√∫squeda:", ["Google Scholar", "Repositorio UPEL"])
    language = st.selectbox("Idioma:", ["Espa√±ol", "Ingl√©s", "Portugu√©s", "Franc√©s"])
    citation_format = st.selectbox("Formato de cita:", ["APA", "UPEL"])
    
    if citation_format == "UPEL":
        upel_work_type = st.selectbox("Tipo de trabajo UPEL:", 
                                    ["Tesis", "Trabajo de Grado", "Tesis de Maestr√≠a", "Tesis Doctoral"])
        st.session_state.upel_work_type = upel_work_type
    
    st.session_state.language = language
    st.session_state.citation_format = citation_format
    
    st.markdown("---")
    st.header("üõ†Ô∏è Herramientas Disponibles")
    st.markdown("""
    - üîç B√∫squeda acad√©mica
    - üìä Calculadora matem√°tica
    - üìù Resumen de art√≠culos
    - üèõÔ∏è Citas APA/UPEL
    - üìö Bibliograf√≠as
    - üìã Tablas comparativas
    - üìÑ Esquemas de investigaci√≥n
    - üéØ T√≠tulos de investigaci√≥n
    - üó∫Ô∏è Mapas conceptuales
    - ‚ùì Preguntas de investigaci√≥n
    - üéØ Objetivos de investigaci√≥n
    """)

# Historial de chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar historial
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input de chat
query = st.chat_input("Escribe tu consulta de investigaci√≥n...")

if query:
    # Preprocesar consulta
    processed_query = query
    
    if search_type == "Repositorio UPEL" and "repositorio upel" not in processed_query.lower():
        processed_query = processed_query + " en el repositorio UPEL"
    
    # A√±adir idioma si no est√° especificado
    language_tags = {
        "Ingl√©s": " en ingl√©s",
        "Portugu√©s": " em portugu√™s", 
        "Franc√©s": " en fran√ßais",
        "Espa√±ol": ""
    }
    if not any(tag in processed_query for tag in ["en ingl√©s", "em portugu√™s", "en fran√ßais"]):
        processed_query += language_tags[language]
    
    # A√±adir formato de cita si es relevante
    if any(keyword in processed_query.lower() for keyword in ["cita", "citation", "cite"]) and not any(format_keyword in processed_query.lower() for format_keyword in ["apa", "upel"]):
        processed_query += f" en formato {citation_format}"

    # Mostrar mensaje del usuario
    with st.chat_message("user"):
        st.markdown(query)
    
    st.session_state.messages.append({"role": "user", "content": query})
    
    # Procesar con el agente
    with st.chat_message("assistant"):
        with st.spinner("Analizando y generando respuesta..."):
            try:
                response = agent.invoke({"input": processed_query})["output"]
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                # Botones de descarga
                col1, col2 = st.columns(2)
                
                with col1:
                    st.download_button(
                        label="üì• Descargar respuesta (Texto)",
                        data=response,
                        file_name="respuesta_investigacion.txt",
                        mime="text/plain"
                    )
                
                # Detectar tipo de contenido para exportaci√≥n Word
                content_types = {
                    "Resumen Estructurado": ["Resumen Estructurado:", "Structured Summary:", "Resumo Estruturado:", "R√©sum√© Structur√©:"],
                    "Tabla Comparativa": ["Tabla Comparativa:", "Comparison Table:", "Tabela Comparativa:", "Tableau Comparatif:"],
                    "Esquema": ["Esquema de Investigaci√≥n:", "Research Outline:", "Esbo√ßo de Pesquisa:", "Plan de Recherche:"],
                    "T√≠tulos": ["Propuestas de T√≠tulos:", "Research Title Proposals:", "Propostas de T√≠tulos:", "Propositions de Titres:"],
                    "Mapa Conceptual": ["Mapa Conceptual:", "Concept Map:", "Mapa Conceitual:", "Carte Conceptuelle:"],
                    "Preguntas": ["Preguntas de Investigaci√≥n:", "Research Questions:", "Perguntas de Pesquisa:", "Questions de Recherche:"],
                    "Objetivos": ["Objetivos de Investigaci√≥n:", "Research Objectives:", "Objetivos de Pesquisa:", "Objectifs de Recherche:"],
                    "Referencias": ["Referencias:", "References:", "Refer√™ncias:", "R√©f√©rences:"]
                }
                
                detected_type = None
                content_for_doc = response
                
                for content_type, keywords in content_types.items():
                    if any(keyword in response for keyword in keywords):
                        detected_type = content_type
                        # Extraer contenido despu√©s del t√≠tulo
                        for keyword in keywords:
                            if keyword in response:
                                content_for_doc = response.split(keyword)[-1].strip()
                                break
                        break
                
                if detected_type:
                    with col2:
                        doc_buffer = generate_word_document(
                            content_for_doc, 
                            language,
                            is_summary=detected_type == "Resumen Estructurado",
                            is_table=detected_type == "Tabla Comparativa", 
                            is_outline=detected_type == "Esquema",
                            is_titles=detected_type == "T√≠tulos",
                            is_concept_map=detected_type == "Mapa Conceptual",
                            is_questions=detected_type == "Preguntas",
                            is_objectives=detected_type == "Objetivos"
                        )
                        
                        file_names = {
                            "Resumen Estructurado": "resumen_estructurado.docx",
                            "Tabla Comparativa": "tabla_comparativa.docx", 
                            "Esquema": "esquema_investigacion.docx",
                            "T√≠tulos": "titulos_investigacion.docx",
                            "Mapa Conceptual": "mapa_conceptual.docx",
                            "Preguntas": "preguntas_investigacion.docx",
                            "Objetivos": "objetivos_investigacion.docx",
                            "Referencias": "referencias_bibliograficas.docx"
                        }
                        
                        st.download_button(
                            label=f"üìÑ Descargar {detected_type} (Word)",
                            data=doc_buffer,
                            file_name=file_names.get(detected_type, "documento.docx"),
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )
                        
            except Exception as e:
                error_msg = f"‚ùå Error al procesar la consulta: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

# Gesti√≥n del historial en el sidebar
with st.sidebar:
    st.markdown("---")
    st.header("üíæ Gesti√≥n del Historial")
    
    if st.session_state.messages:
        history_text = "\n\n".join([f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.messages])
        
        st.download_button(
            label="üìã Descargar historial completo",
            data=history_text,
            file_name="historial_conversacion.txt",
            mime="text/plain"
        )
        
        if st.button("üóëÔ∏è Limpiar historial", type="secondary"):
            st.session_state.messages = []
            memory.clear()
            st.rerun()

# Informaci√≥n de ayuda
with st.sidebar:
    st.markdown("---")
    st.header("‚ÑπÔ∏è Ejemplos de consultas")
    st.markdown("""
    - *"Busca art√≠culos sobre inteligencia artificial en educaci√≥n despu√©s de 2020"*
    - *"Genera un resumen estructurado del primer art√≠culo sobre machine learning"*  
    - *"Crea una bibliograf√≠a en formato APA sobre cambio clim√°tico"*
    - *"Genera 5 preguntas de investigaci√≥n sobre educaci√≥n virtual"*
    - *"Dame un esquema de investigaci√≥n sobre sostenibilidad ambiental"*
    """)
