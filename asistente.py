import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import google.generativeai as genai
from google.generativeai import types
import io
import csv
from docx import Document
from semantic_scholar import SemanticScholar
import re

# Clase Agente con memoria
class AgenteConMemoria:
    def __init__(self):
        self.memoria = []
    
    def agregar_memoria(self, entrada, salida):
        self.memoria.append({"entrada": entrada, "salida": salida, "timestamp": datetime.now()})
    
    def obtener_memoria(self):
        return self.memoria
    
    def limpiar_memoria(self):
        self.memoria = []

# FUNCIONES DE B√öSQUEDA MEJORADAS
def buscar_semantic_scholar(query, max_results=5):
    """B√∫squeda gratuita en Semantic Scholar"""
    articulos = []
    try:
        scholar = SemanticScholar()
        resultados = scholar.search_paper(query, limit=max_results)
        count = 0
        for paper in resultados:
            articulos.append({
                "titulo": paper.title,
                "autor": ". ".join([author['name'] for author in paper.authors]) if paper.authors else 'Desconocido',
                "a√±o": str(paper.year) if paper.year else "s.f.",
                "publicacion": paper.venue if paper.venue else "",
                "url": paper.url if paper.url else "",
                "fuente": "Semantic Scholar"
            })
            count += 1
            if count >= max_results:
                break
        time.sleep(0.5)
    except Exception as e:
        st.error(f"Error en Semantic Scholar: {e}")
    return articulos

def buscar_scielo(query, max_results=5):
    """B√∫squeda gratuita en SciELO"""
    articulos = []
    try:
        url = f"https://search.scielo.org/?q={query}&lang=es"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        soup = BeautifulSoup(response.text, 'html.parser')
        resultados = soup.select(".item")
        
        for resultado in resultados[:max_results]:
            try:
                titulo_elem = resultado.select_one(".title")
                autores_elem = resultado.select_one(".authors")
                enlace_elem = resultado.select_one(".line a")
                
                titulo = titulo_elem.text.strip() if titulo_elem else "Sin titulo"
                autores = autores_elem.text.strip() if autores_elem else "Desconocido"
                enlace = enlace_elem["href"] if enlace_elem else ""
                
                articulos.append({
                    "titulo": titulo,
                    "autor": autores,
                    "a√±o": "s.f.",
                    "publicacion": "SciELO",
                    "url": f"https:{enlace}" if enlace else "",
                    "fuente": "SciELO"
                })
            except Exception:
                continue
    except Exception as e:
        st.error(f"Error en SciELO: {e}")
    return articulos

# FUNCIONES DE PROCESAMIENTO DE LENGUAJE MEJORADAS
def extraer_tema_principal(user_input):
    """Extrae el tema real de investigaci√≥n del input del usuario"""
    try:
        # Patr√≥n para detectar preguntas de investigaci√≥n
        patron_pregunta = r'[¬ø]?(qu√©|cuales|como|por qu√©|d√≥nde|cu√°ndo)\s+([^?]+)[?]'
        coincidencia = re.search(patron_pregunta, user_input.lower())
        
        if coincidencia:
            return coincidencia.group(2).strip()
        
        # Eliminar palabras de solicitud metodol√≥gica
        palabras_excluir = ['formula', 'planteamiento', 'problema', 'interrogante', 
                           'redacta', 'elabora', 'desarrolla', 'haz', 'crea', 'genera',
                           'para la', 'sobre', 'acerca de']
        
        tema = user_input.lower()
        for palabra in palabras_excluir:
            tema = tema.replace(palabra, '')
        
        # Limpiar espacios extras y caracteres especiales
        tema = re.sub(r'[^\w\s]', '', tema)
        tema = ' '.join(tema.split())
        
        return tema.strip() if tema.strip() else user_input
    except Exception:
        return user_input

def detectar_tipo_solicitud(user_input):
    """Detecta el tipo de solicitud del usuario"""
    input_lower = user_input.lower()
    
    if any(palabra in input_lower for palabra in ['planteamiento', 'problema', 'pregunta investigaci√≥n']):
        return "planteamiento"
    elif any(palabra in input_lower for palabra in ['objetivos', 'metas', 'prop√≥sitos']):
        return "objetivos"
    elif any(palabra in input_lower for palabra in ['metodolog√≠a', 'm√©todo', 'dise√±o', 'enfoque']):
        return "metodologia"
    elif any(palabra in input_lower for palabra in ['variables', 'operacional']):
        return "variables"
    elif any(palabra in input_lower for palabra in ['resumen', 's√≠ntesis', 'analizar']):
        return "resumen"
    else:
        return "general"

# FUNCIONES DE GENERACI√ìN MEJORADAS
def generar_planteamiento_estructurado(tema, contexto=""):
    """Genera un planteamiento del problema bien estructurado"""
    try:
        client = genai.Client()
        
        prompt = f"""
        Como experto en metodolog√≠a de investigaci√≥n, genera un PLANTEAMIENTO DEL PROBLEMA 
        acad√©mico y profesional sobre el tema: "{tema}"
        
        Contexto adicional: {contexto}
        
        Estructura tu respuesta en los siguientes componentes:
        
        # DESCRIPCI√ìN DEL PROBLEMA
        [Describe claramente el problema de investigaci√≥n, su contexto y magnitud]
        
        # JUSTIFICACI√ìN
        [Explica la relevancia acad√©mica, pr√°ctica y social de investigar este problema]
        
        # DELIMITACI√ìN
        [Especifica el alcance, poblaci√≥n y contexto del estudio]
        
        # PREGUNTAS DE INVESTIGACI√ìN
        [Formula 3-5 preguntas de investigaci√≥n espec√≠ficas y relevantes]
        
        Usa un lenguaje acad√©mico formal en espa√±ol. S√© espec√≠fico y evgeneralizaciones.
        """
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        
        return response.text.strip()
        
    except Exception as e:
        return f"Error al generar planteamiento: {e}"

def generar_objetivos_estructurados(tema, contexto=""):
    """Genera objetivos de investigaci√≥n estructurados"""
    try:
        client = genai.Client()
        
        prompt = f"""
        Para la investigaci√≥n sobre: "{tema}"
        
        Contexto: {contexto}
        
        Genera objetivos de investigaci√≥n que incluyan:
        
        OBJETIVO GENERAL:
        [Un objetivo principal amplio]
        
        OBJETIVOS ESPEC√çFICOS:
        1. [Objetivo espec√≠fico 1]
        2. [Objetivo espec√≠fico 2] 
        3. [Objetivo espec√≠fico 3]
        4. [Objetivo espec√≠fico 4]
        
        Los objetivos deben ser SMART (espec√≠ficos, medibles, alcanzables, relevantes, temporales)
        y coherentes con el tema de investigaci√≥n.
        """
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        
        return response.text.strip()
        
    except Exception as e:
        return f"Error al generar objetivos: {e}"

def generar_respuesta_general(tema, user_input):
    """Genera respuesta general del asistente"""
    try:
        client = genai.Client()
        
        prompt = f"""
        Eres un asistente de investigaci√≥n acad√©mica especializado en {tema}.
        
        El usuario pregunta: "{user_input}"
        
        Proporciona una respuesta √∫til, acad√©mica y bien fundamentada. Si es apropiado, sugiere:
        - Enfoques metodol√≥gicos
        - Fuentes de datos relevantes
        - Conceptos clave para investigar
        - Posibles l√≠neas de investigaci√≥n
        
        Respuesta en espa√±ol, formato claro y profesional.
        """
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.7)
        )
        
        return response.text.strip()
        
    except Exception as e:
        return f"Error en la respuesta: {e}"

# FUNCI√ìN DE CHAT COMPLETAMENTE REDISE√ëADA
def chat_con_agente(agente, user_input, contexto_usuario=""):
    """Funci√≥n principal del chat completamente mejorada"""
    try:
        # Extraer el tema real de la consulta
        tema_real = extraer_tema_principal(user_input)
        tipo_solicitud = detectar_tipo_solicitud(user_input)
        
        # Generar respuesta seg√∫n el tipo de solicitud
        if tipo_solicitud == "planteamiento":
            respuesta = generar_planteamiento_estructurado(tema_real, contexto_usuario)
            
        elif tipo_solicitud == "objetivos":
            respuesta = generar_objetivos_estructurados(tema_real, contexto_usuario)
            
        elif tipo_solicitud == "metodologia":
            respuesta = generar_sugerencias_metodologicas("", contexto_usuario or tema_real)
            
        elif tipo_solicitud == "variables":
            respuesta = sugerir_variables_operativas("", contexto_usuario or tema_real)
            
        elif tipo_solicitud == "resumen":
            if hasattr(st.session_state, 'resumen_actual'):
                respuesta = st.session_state.resumen_actual
            else:
                respuesta = "Primero realiza una b√∫squeda acad√©mica para generar res√∫menes."
                
        else:
            respuesta = generar_respuesta_general(tema_real, user_input)
        
        # Guardar en memoria
        agente.agregar_memoria(user_input, respuesta)
        return respuesta
        
    except Exception as e:
        return f"Error en el chat: {e}"

# FUNCIONES ORIGINALES (MANTENIDAS)
def preparar_texto_para_gemini(articulos):
    texto = ""
    for art in articulos:
        texto += f"T√≠tulo: {art['titulo']}\nAutores: {art['autor']}\nA√±o: {art['a√±o']}\nURL: {art['url']}\n\n"
    return texto

def resumir_articulos_con_gemini(texto):
    try:
        client = genai.Client()
        prompt = (f"Analiza estos art√≠culos acad√©micos para resumir temas principales, "
                 f"vac√≠os de investigaci√≥n y sugerir l√≠neas de trabajo para un proyecto:\n\n{texto}")
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.2)
        )
        return response.text
    except Exception as e:
        return f"Error al generar resumen: {e}"

def generar_planteamiento_problema(texto_resumen, contexto_usuario):
    try:
        client = genai.Client()
        prompt = (
            f"Con base en la siguiente s√≠ntesis de literatura cient√≠fica:\n{texto_resumen}\n\n"
            f"Considerando que el investigador se interesa en: {contexto_usuario}\n"
            "Genera un planteamiento del problema estructurado para un proyecto de investigaci√≥n que incluya:\n"
            ". Descripci√≥n clara del problema\n"
            ". Justificaci√≥n de la investigaci√≥n\n"
            ". Delimitaci√≥n del campo o poblaci√≥n\n"
            ". Preguntas de investigaci√≥n bien formuladas\n"
        )
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        return response.text
    except Exception as e:
        return f"Error al generar planteamiento: {e}"

def generar_objetivos_investigacion(texto_resumen, contexto_usuario):
    try:
        client = genai.Client()
        prompt = (
            f"Con base en la siguiente s√≠ntesis de literatura cient√≠fica y el contexto del investigador:\n{texto_resumen}\n\n"
            f"Considerando que el investigador desea enfocarse en: {contexto_usuario}\n"
            "Genera los objetivos de investigaci√≥n para un proyecto acad√©mico que incluyan:\n"
            "- Un objetivo general\n"
            "- Tres a cinco objetivos espec√≠ficos coherentes con el problema y la justificaci√≥n\n"
        )
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        return response.text
    except Exception as e:
        return f"Error al generar objetivos: {e}"

def sugerir_variables_operativas(texto_resumen, contexto_usuario):
    try:
        client = genai.Client()
        prompt = (
            f"Basado en esta s√≠ntesis de literatura cient√≠fica:\n{texto_resumen}\n\n"
            f"Considerando que el investigador trabaja en el contexto: {contexto_usuario}\n"
            "Genera una propuesta de variables de investigaci√≥n (dependientes, independientes, mediadoras, moderadoras) "
            "y sus definiciones operativas claras, espec√≠ficas y coherentes con el problema y objetivos de investigaci√≥n."
        )
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        return response.text
    except Exception as e:
        return f"Error al generar variables: {e}"

def generar_sugerencias_metodologicas(texto_resumen, contexto_usuario):
    try:
        client = genai.Client()
        prompt = (
            f"Considerando la siguiente s√≠ntesis de literatura cient√≠fica:\n{texto_resumen}\n\n"
            f"Y el contexto de investigaci√≥n: {contexto_usuario}\n"
            "Genera sugerencias detalladas sobre:\n"
            "- Tipo o enfoque metodol√≥gico (cuantitativo, cualitativo, mixto)\n"
            "- Dise√±o de investigaci√≥n apropiado\n"
            "- T√©cnicas e instrumentos de recolecci√≥n de datos recomendadas\n"
            "- Estrategias para el an√°lisis de datos\n"
            "Estas sugerencias deben ser coherentes con el planteamiento del problema y los objetivos de investigaci√≥n."
        )
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(temperature=0.3)
        )
        return response.text
    except Exception as e:
        return f"Error al generar sugerencias metodol√≥gicas: {e}"

def generar_bibliografia(referencias, estilo="APA"):
    def formatear_cita(ref):
        autor = ref.get("autor", "Desconocido").strip()
        a√±o = ref.get("a√±o", "").strip() or "s.f."
        titulo = ref.get("titulo", "").strip()
        publicacion = ref.get("publicacion", "").strip()
        url = ref.get("url", "").strip()

        if estilo.upper() == "APA":
            partes = []
            partes.append(f"{autor} ({a√±o})")
            if titulo:
                partes.append(f"{titulo}.")
            if publicacion:
                partes.append(f"{publicacion}.")
            cita = " ".join(partes)
            if url:
                cita += f" Recuperado de {url}"
        elif estilo.upper() == "UPEL":
            partes = []
            partes.append(f"{autor}. ({a√±o}).")
            if titulo:
                partes.append(f"{titulo}.")
            if publicacion:
                partes.append(f"{publicacion}.")
            cita = " ".join(partes)
            if url:
                cita += f" Disponible en: {url}"
        else:
            cita = f"{autor}, {a√±o}, {titulo}"
        return " ".join(cita.split())

    bibliografia = [formatear_cita(ref) for ref in referencias]
    return "\n\n".join(bibliografia)

# FUNCI√ìN PRINCIPAL DE STREAMLIT
def main():
    # Configuraci√≥n de p√°gina
    st.set_page_config(
        page_title="Asistente de Investigaci√≥n Inteligente",
        page_icon="üî¨",
        layout="wide"
    )
    
    # Header principal
    st.markdown("""
    <div class="main-header" style="text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 20px;">
        <h1>üî¨ Asistente de Investigaci√≥n Inteligente para Postgrado</h1>
        <p>Chatbot mejorado con procesamiento avanzado de lenguaje natural</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/2913/2913517.png", width=80)
        st.title("Configuraci√≥n")
        
        st.markdown("---")
        st.subheader("üîç B√∫squeda")
        max_results = st.slider("Resultados por base", 1, 10, 5)
        
        st.markdown("---")
        st.subheader("üì§ Exportaci√≥n")
        formato_exportacion = st.selectbox("Formato preferido", ["CSV", "DOCX", "TXT"])
        
        st.markdown("---")
        st.subheader("‚ÑπÔ∏è Informaci√≥n")
        st.info("""
        **Bases de datos gratuitas:**
        - Semantic Scholar
        - SciELO
        
        **Funcionalidades MEJORADAS:**
        - Chatbot inteligente con NLP
        - Detecci√≥n autom√°tica de temas
        - Generaci√≥n contextualizada
        - Exportaci√≥n de resultados
        """)
    
    # Inicializar session state
    if 'articulos' not in st.session_state:
        st.session_state.articulos = []
    if 'agente' not in st.session_state:
        st.session_state.agente = AgenteConMemoria()
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'contexto_actual' not in st.session_state:
        st.session_state.contexto_actual = ""
    
    # Pesta√±as principales
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üè† Inicio", 
        "üîç B√∫squeda Acad√©mica", 
        "üìä Generar Proyecto", 
        "üí¨ Chat con Agente",
        "üìÖ Exportar Resultados"
    ])
    
    # Pesta√±a de Inicio
    with tab1:
        st.markdown("### üí° Bienvenido al Asistente de Investigaci√≥n Inteligente")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            ### üöÄ ¬øQu√© puedes hacer con la VERSI√ìN MEJORADA?
            
            **üîç Chatbot Inteligente MEJORADO**
            - Procesamiento avanzado de lenguaje natural
            - Detecci√≥n autom√°tica de temas de investigaci√≥n
            - Generaci√≥n contextualizada de planteamientos
            - Respuestas espec√≠ficas y relevantes
            
            **üìö B√∫squeda Acad√©mica Integrada**
            - Buscar en Semantic Scholar (Internacional)
            - Buscar en SciELO (Am√©rica Latina)
            - Resultados en tiempo real
            - Filtrado por relevancia
            
            **ü§ñ An√°lisis con Inteligencia Artificial**
            - Res√∫menes autom√°ticos de literatura
            - Detecci√≥n de tendencias de investigaci√≥n
            - Identificaci√≥n de vac√≠os en la literatura
            - Sugerencias de l√≠neas de investigaci√≥n
            
            **üìã Desarrollo de Proyectos**
            - Generar planteamientos de problema
            - Definir objetivos de investigaci√≥n
            - Sugerir variables operativas
            - Proponer metodolog√≠as apropiadas
            """)
        
        with col2:
            st.markdown("""
            ### üéØ Comenzar es f√°cil:
            
            1. **Ve a la pesta√±a üí¨ Chat con Agente**
            2. **Escribe tu pregunta naturalmente**
            3. **El sistema detectar√° autom√°ticamente tu tema**
            4. **Recibe respuestas contextualizadas**
            
            ### üí¨ Ejemplos de preguntas:
            - *"Formula el planteamiento del problema sobre competencias digitales y resiliencia en entornos automatizados"*
            - *"Genera objetivos para investigaci√≥n sobre inteligencia artificial en educaci√≥n"*
            - *"Sugiere metodolog√≠a para estudiar impacto de redes sociales"*
            
            ### üóÉÔ∏è Bases disponibles:
            ‚òë Semantic Scholar  
            ‚òë SciELO  
            ‚òë Acceso gratuito  
            """)
        
        st.markdown("---")
        st.subheader("üìä Estad√≠sticas de la sesi√≥n")
        col_stats1, col_stats2, col_stats3 = st.columns(3)
        with col_stats1:
            st.metric("Art√≠culos encontrados", len(st.session_state.articulos))
        with col_stats2:
            st.metric("Consultas al agente", len(st.session_state.agente.obtener_memoria()))
        with col_stats3:
            st.metric("Mensajes en chat", len(st.session_state.chat_history))
    
    # Pesta√±a de B√∫squeda Acad√©mica
    with tab2:
        st.markdown("### üîç B√∫squeda en Bases Acad√©micas")
        
        col_search1, col_search2 = st.columns([2, 1])
        
        with col_search1:
            consulta = st.text_input(
                "üîç Tema de investigaci√≥n:",
                placeholder="Ej: inteligencia artificial educaci√≥n secundaria",
                help="Describe tu tema de investigaci√≥n con palabras clave espec√≠ficas"
            )
        
        with col_search2:
            contexto = st.text_input(
                "üéØ Contexto espec√≠fico:",
                placeholder="Ej: an√°lisis de impacto en Venezuela",
                help="Especifica el contexto o enfoque particular"
            )
        
        # Selecci√≥n de bases de datos
        st.subheader("Selecciona las bases de datos:")
        col_db1, col_db2 = st.columns(2)
        
        with col_db1:
            usar_semantic = st.checkbox("Semantic Scholar", value=True, help="Art√≠culos en ingl√©s e internacionales")
        with col_db2:
            usar_scielo = st.checkbox("SciELO", value=True, help="Revistas cient√≠ficas de Am√©rica Latina")
        
        if st.button("üîç Ejecutar B√∫squeda Integral", type="primary", use_container_width=True):
            if not consulta:
                st.error("üìå Por favor ingresa un tema de investigaci√≥n")
            else:
                with st.spinner("üîç Buscando en bases acad√©micas..."):
                    # Ejecutar b√∫squedas
                    articulos_encontrados = []
                    
                    if usar_semantic:
                        with st.expander("üåê Semantic Scholar", expanded=True):
                            resultados_ss = buscar_semantic_scholar(consulta, max_results)
                            articulos_encontrados.extend(resultados_ss)
                            st.success(f"üìÑ Encontrados: {len(resultados_ss)} art√≠culos")
                    
                    if usar_scielo:
                        with st.expander("üåé SciELO", expanded=True):
                            resultados_scielo = buscar_scielo(consulta, max_results)
                            articulos_encontrados.extend(resultados_scielo)
                            st.success(f"üìÑ Encontrados: {len(resultados_scielo)} art√≠culos")
                    
                    # Guardar resultados
                    st.session_state.articulos = articulos_encontrados
                    st.session_state.consulta_actual = consulta
                    st.session_state.contexto_actual = contexto
                    
                    if articulos_encontrados:
                        st.success(f"‚úÖ B√∫squeda completada! Se encontraron {len(articulos_encontrados)} art√≠culos")
                        
                        # Generar y mostrar resumen con Gemini
                        with st.expander("ü§ñ Resumen y An√°lisis con IA", expanded=True):
                            texto_gemini = preparar_texto_para_gemini(articulos_encontrados)
                            if texto_gemini.strip():
                                resumen = resumir_articulos_con_gemini(texto_gemini)
                                st.markdown(resumen)
                                st.session_state.resumen_actual = resumen
                            else:
                                st.warning("No se encontraron art√≠culos. Intenta con otros t√©rminos de b√∫squeda.")
                    else:
                        st.warning("No se encontraron art√≠culos con los criterios especificados.")
        
        # Mostrar resultados detallados
        if st.session_state.articulos:
            st.markdown("---")
            st.subheader("üìö Art√≠culos Encontrados")
            
            for i, articulo in enumerate(st.session_state.articulos):
                with st.expander(f"üìñ {articulo['titulo']}", key=f"art_{i}"):
                    col_info1, col_info2 = st.columns([3, 1])
                    
                    with col_info1:
                        st.write(f"**Autores:** {articulo['autor']}")
                        st.write(f"**A√±o:** {articulo['a√±o']}")
                        st.write(f"**Publicaci√≥n:** {articulo['publicacion']}")
                        st.write(f"**Fuente:** {articulo['fuente']}")
                    
                    with col_info2:
                        if articulo['url']:
                            st.markdown(f"[üîó Enlace al art√≠culo]({articulo['url']})")
                        else:
                            st.write("üîó Enlace no disponible")
    
    # Pesta√±a de Generar Proyecto
    with tab3:
        st.markdown("### üìä Generar Elementos de Investigaci√≥n")
        
        if not st.session_state.articulos:
            st.warning("‚ö†Ô∏è Primero realiza una b√∫squeda en la pesta√±a anterior para generar contenido.")
        else:
            col_gen1, col_gen2 = st.columns(2)
            
            with col_gen1:
                if st.button("üìù Generar Planteamiento del Problema", use_container_width=True):
                    with st.spinner("Generando planteamiento del problema..."):
                        if hasattr(st.session_state, 'resumen_actual'):
                            planteamiento = generar_planteamiento_problema(
                                st.session_state.resumen_actual,
                                st.session_state.contexto_actual
                            )
                            st.session_state.planteamiento = planteamiento
                            st.markdown(planteamiento)
                        else:
                            st.error("Primero genera un resumen en la pesta√±a de B√∫squeda")
            
            with col_gen2:
                if st.button("üéØ Generar Objetivos de Investigaci√≥n", use_container_width=True):
                    with st.spinner("Generando objetivos de investigaci√≥n..."):
                        if hasattr(st.session_state, 'resumen_actual'):
                            objetivos = generar_objetivos_investigacion(
                                st.session_state.resumen_actual,
                                st.session_state.contexto_actual
                            )
                            st.session_state.objetivos = objetivos
                            st.markdown(objetivos)
                        else:
                            st.error("Primero genera un resumen en la pesta√±a de B√∫squeda")
            
            st.markdown("---")
            col_gen3, col_gen4 = st.columns(2)
            
            with col_gen3:
                if st.button("üìä Sugerir Variables Operativas", use_container_width=True):
                    with st.spinner("Generando variables operativas..."):
                        if hasattr(st.session_state, 'resumen_actual'):
                            variables = sugerir_variables_operativas(
                                st.session_state.resumen_actual,
                                st.session_state.contexto_actual
                            )
                            st.session_state.variables = variables
                            st.markdown(variables)
                        else:
                            st.error("Primero genera un resumen en la pesta√±a de B√∫squeda")
            
            with col_gen4:
                if st.button("üî¨ Generar Sugerencias Metodol√≥gicas", use_container_width=True):
                    with st.spinner("Generando sugerencias metodol√≥gicas..."):
                        if hasattr(st.session_state, 'resumen_actual'):
                            metodologia = generar_sugerencias_metodologicas(
                                st.session_state.resumen_actual,
                                st.session_state.contexto_actual
                            )
                            st.session_state.metodologia = metodologia
                            st.markdown(metodologia)
                        else:
                            st.error("Primero genera un resumen en la pesta√±a de B√∫squeda")
    
    # Pesta√±a de Chat con Agente - COMPLETAMENTE REDISE√ëADA
    with tab4:
        st.markdown("### üí¨ Chat Inteligente con el Agente de Investigaci√≥n")
        
        st.info("""
        üéØ **Pregunta naturalmente sobre:**
        - Planteamientos de problemas de investigaci√≥n
        - Objetivos y metodolog√≠as
        - An√°lisis de datos y variables
        - Redacci√≥n acad√©mica y referencias
        - Dise√±o de instrumentos de investigaci√≥n
        
        üí° **Ejemplo:** *"Formula el planteamiento del problema sobre competencias digitales en entornos automatizados"*
        """)
        
        # Configuraci√≥n de contexto
        st.session_state.contexto_actual = st.text_input(
            "üéØ Contexto de investigaci√≥n (opcional):",
            placeholder="Ej: educaci√≥n superior en Latinoam√©rica",
            help="Proporciona contexto para respuestas m√°s precisas"
        )
        
        # Mostrar historial de chat
        for mensaje in st.session_state.chat_history:
            with st.chat_message(mensaje["role"]):
                st.markdown(mensaje["content"])
        
        # Input de chat
        if prompt := st.chat_input("Escribe tu pregunta sobre investigaci√≥n..."):
            # Agregar mensaje del usuario
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Respuesta del agente MEJORADO
            with st.chat_message("assistant"):
                with st.spinner("ü§î Analizando tu consulta..."):
                    # Usar la funci√≥n de chat mejorada
                    respuesta = chat_con_agente(
                        st.session_state.agente, 
                        prompt, 
                        st.session_state.contexto_actual
                    )
                    st.markdown(respuesta)
            
            # Agregar respuesta al historial
            st.session_state.chat_history.append({"role": "assistant", "content": respuesta})
        
        # Botones de acci√≥n
        col_chat1, col_chat2, col_chat3 = st.columns(3)
        with col_chat1:
            if st.button("üóëÔ∏è Limpiar Conversaci√≥n", use_container_width=True):
                st.session_state.chat_history = []
                st.session_state.agente.limpiar_memoria()
                st.rerun()
        
        with col_chat2:
            if st.button("üí° Ejemplo de Planteamiento", use_container_width=True):
                ejemplo = "Formula el planteamiento del problema sobre competencias digitales para la resiliencia en entornos automatizados con IA"
                st.session_state.chat_history.append({"role": "user", "content": ejemplo})
                with st.chat_message("assistant"):
                    with st.spinner("ü§î Generando ejemplo..."):
                        respuesta = chat_con_agente(
                            st.session_state.agente, 
                            ejemplo, 
                            "entornos laborales digitalizados"
                        )
                        st.markdown(respuesta)
                st.session_state.chat_history.append({"role": "assistant", "content": respuesta})
                st.rerun()
        
        with col_chat3:
            if st.button("üìä Ver Estad√≠sticas", use_container_width=True):
                memoria = st.session_state.agente.obtener_memoria()
                st.info(f"**Estad√≠sticas del Agente:**\n- Consultas procesadas: {len(memoria)}\n- Tema actual: {st.session_state.contexto_actual}")
    
    # Pesta√±a de Exportar Resultados
    with tab5:
        st.markdown("### üì§ Exportar Resultados de Investigaci√≥n")
        
        if not st.session_state.articulos:
            st.warning("üìå No hay resultados para exportar. Realiza primero una b√∫squeda.")
        else:
            col_exp1, col_exp2, col_exp3 = st.columns(3)
            
            with col_exp1:
                st.subheader("üìö Art√≠culos Encontrados")
                
                # Exportar CSV
                campos_csv = ["titulo", "autor", "a√±o", "publicacion", "fuente", "url"]
                articulos_exportar = []
                
                for art in st.session_state.articulos:
                    articulos_exportar.append({
                        "titulo": art.get("titulo", ""),
                        "autor": art.get("autor", ""),
                        "a√±o": art.get("a√±o", "s.f."),
                        "publicacion": art.get("publicacion", ""),
                        "fuente": art.get("fuente", ""),
                        "url": art.get("url", "")
                    })
                
                # Crear CSV en memoria
                output = io.StringIO()
                writer = csv.DictWriter(output, fieldnames=campos_csv)
                writer.writeheader()
                for item in articulos_exportar:
                    writer.writerow(item)
                csv_data = output.getvalue()
                
                st.download_button(
                    label="üì• Descargar Art√≠culos (CSV)",
                    data=csv_data,
                    file_name=f"articulos_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            with col_exp2:
                st.subheader("üìÑ Documentos Generados")
                
                if 'planteamiento' in st.session_state:
                    # Crear DOCX en memoria
                    doc = Document()
                    doc.add_heading("Planteamiento del Problema", level=1)
                    doc.add_paragraph(st.session_state.planteamiento)
                    buffer = io.BytesIO()
                    doc.save(buffer)
                    buffer.seek(0)
                    
                    st.download_button(
                        label="üìÑ Planteamiento (DOCX)",
                        data=buffer,
                        file_name="planteamiento_problema.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        use_container_width=True
                    )
                
                if 'objetivos' in st.session_state:
                    # Exportar objetivos como TXT
                    objetivos_txt = st.session_state.objetivos
                    st.download_button(
                        label="üéØ Objetivos (TXT)",
                        data=objetivos_txt,
                        file_name="objetivos_investigacion.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
            
            with col_exp3:
                st.subheader("üìñ Bibliograf√≠a")
                
                # Generar bibliograf√≠a
                referencias = []
                for art in st.session_state.articulos:
                    ref = {
                        "autor": art["autor"],
                        "a√±o": art["a√±o"] if art["a√±o"] else "s.f.",
                        "titulo": art["titulo"],
                        "publicacion": art["publicacion"],
                        "url": art["url"],
                    }
                    referencias.append(ref)
                
                bibliografia_apa = generar_bibliografia(referencias, estilo="APA")
                
                st.download_button(
                    label="üìö Bibliografia APA (TXT)",
                    data=bibliografia_apa,
                    file_name="bibliografia_APA.txt",
                    mime="text/plain",
                    use_container_width=True
                )
            
            st.markdown("---")
            st.subheader("üìä Estad√≠sticas de Exportaci√≥n")
            
            col_stats1, col_stats2, col_stats3, col_stats4 = st.columns(4)
            
            with col_stats1:
                st.metric("Art√≠culos", len(st.session_state.articulos))
            
            with col_stats2:
                fuentes = set(art['fuente'] for art in st.session_state.articulos)
                st.metric("Fuentes", len(fuentes))
            
            with col_stats3:
                a√±os = [art['a√±o'] for art in st.session_state.articulos if art['a√±o'].isdigit()]
                if a√±os:
                    st.metric("Rango de a√±os", f"{min(a√±os)}-{max(a√±os)}")
                else:
                    st.metric("Rango de a√±os", "N/A")
            
            with col_stats4:
                st.metric("Formatos", "CSV, DOCX, TXT")

if __name__ == "__main__":
    main()
